// Code is generated by go generate. DO NOT EDIT.
package keibi

import (
	"context"
	"github.com/turbot/steampipe-plugin-sdk/plugin"
	aws "gitlab.com/keibiengine/keibi-engine/pkg/aws/model"
)

// ==========================  START: AccessAnalyzerAnalyzer =============================

type AccessAnalyzerAnalyzer struct {
	Description   aws.AccessAnalyzerAnalyzerDescription `json:"description"`
	Metadata      aws.Metadata                          `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	SourceID      string                                `json:"source_id"`
}

type AccessAnalyzerAnalyzerHit struct {
	ID      string                 `json:"_id"`
	Score   float64                `json:"_score"`
	Index   string                 `json:"_index"`
	Type    string                 `json:"_type"`
	Version int64                  `json:"_version,omitempty"`
	Source  AccessAnalyzerAnalyzer `json:"_source"`
	Sort    []interface{}          `json:"sort"`
}

type AccessAnalyzerAnalyzerHits struct {
	Total SearchTotal                 `json:"total"`
	Hits  []AccessAnalyzerAnalyzerHit `json:"hits"`
}

type AccessAnalyzerAnalyzerSearchResponse struct {
	PitID string                     `json:"pit_id"`
	Hits  AccessAnalyzerAnalyzerHits `json:"hits"`
}

type AccessAnalyzerAnalyzerPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewAccessAnalyzerAnalyzerPaginator(filters []BoolFilter, limit *int64) (AccessAnalyzerAnalyzerPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_accessanalyzer_analyzer", filters, limit)
	if err != nil {
		return AccessAnalyzerAnalyzerPaginator{}, err
	}

	p := AccessAnalyzerAnalyzerPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AccessAnalyzerAnalyzerPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p AccessAnalyzerAnalyzerPaginator) NextPage(ctx context.Context) ([]AccessAnalyzerAnalyzer, error) {
	var response AccessAnalyzerAnalyzerSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AccessAnalyzerAnalyzer
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listAccessAnalyzerAnalyzerFilters = map[string]string{
	"type": "description.Analyzer.Type",
}

func ListAccessAnalyzerAnalyzer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAccessAnalyzerAnalyzer")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewAccessAnalyzerAnalyzerPaginator(buildFilter(d.KeyColumnQuals, listAccessAnalyzerAnalyzerFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAccessAnalyzerAnalyzerFilters = map[string]string{
	"name": "description.Analyzer.Name",
}

func GetAccessAnalyzerAnalyzer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAccessAnalyzerAnalyzer")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewAccessAnalyzerAnalyzerPaginator(buildFilter(d.KeyColumnQuals, getAccessAnalyzerAnalyzerFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AccessAnalyzerAnalyzer =============================

// ==========================  START: ApiGatewayStage =============================

type ApiGatewayStage struct {
	Description   aws.ApiGatewayStageDescription `json:"description"`
	Metadata      aws.Metadata                   `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	SourceID      string                         `json:"source_id"`
}

type ApiGatewayStageHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  ApiGatewayStage `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type ApiGatewayStageHits struct {
	Total SearchTotal          `json:"total"`
	Hits  []ApiGatewayStageHit `json:"hits"`
}

type ApiGatewayStageSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  ApiGatewayStageHits `json:"hits"`
}

type ApiGatewayStagePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewApiGatewayStagePaginator(filters []BoolFilter, limit *int64) (ApiGatewayStagePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_apigateway_stage", filters, limit)
	if err != nil {
		return ApiGatewayStagePaginator{}, err
	}

	p := ApiGatewayStagePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ApiGatewayStagePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ApiGatewayStagePaginator) NextPage(ctx context.Context) ([]ApiGatewayStage, error) {
	var response ApiGatewayStageSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ApiGatewayStage
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listApiGatewayStageFilters = map[string]string{}

func ListApiGatewayStage(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListApiGatewayStage")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewApiGatewayStagePaginator(buildFilter(d.KeyColumnQuals, listApiGatewayStageFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getApiGatewayStageFilters = map[string]string{
	"name":        "description.Stage.StageName",
	"rest_api_id": "description.RestApiId",
}

func GetApiGatewayStage(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetApiGatewayStage")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewApiGatewayStagePaginator(buildFilter(d.KeyColumnQuals, getApiGatewayStageFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ApiGatewayStage =============================

// ==========================  START: ApiGatewayV2Stage =============================

type ApiGatewayV2Stage struct {
	Description   aws.ApiGatewayV2StageDescription `json:"description"`
	Metadata      aws.Metadata                     `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	SourceID      string                           `json:"source_id"`
}

type ApiGatewayV2StageHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  ApiGatewayV2Stage `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type ApiGatewayV2StageHits struct {
	Total SearchTotal            `json:"total"`
	Hits  []ApiGatewayV2StageHit `json:"hits"`
}

type ApiGatewayV2StageSearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  ApiGatewayV2StageHits `json:"hits"`
}

type ApiGatewayV2StagePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewApiGatewayV2StagePaginator(filters []BoolFilter, limit *int64) (ApiGatewayV2StagePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_apigatewayv2_stage", filters, limit)
	if err != nil {
		return ApiGatewayV2StagePaginator{}, err
	}

	p := ApiGatewayV2StagePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ApiGatewayV2StagePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ApiGatewayV2StagePaginator) NextPage(ctx context.Context) ([]ApiGatewayV2Stage, error) {
	var response ApiGatewayV2StageSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ApiGatewayV2Stage
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listApiGatewayV2StageFilters = map[string]string{}

func ListApiGatewayV2Stage(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListApiGatewayV2Stage")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewApiGatewayV2StagePaginator(buildFilter(d.KeyColumnQuals, listApiGatewayV2StageFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getApiGatewayV2StageFilters = map[string]string{
	"api_id": "description.ApiId",
	"name":   "description.Stage.StageName",
}

func GetApiGatewayV2Stage(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetApiGatewayV2Stage")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewApiGatewayV2StagePaginator(buildFilter(d.KeyColumnQuals, getApiGatewayV2StageFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ApiGatewayV2Stage =============================

// ==========================  START: ElasticBeanstalkEnvironment =============================

type ElasticBeanstalkEnvironment struct {
	Description   aws.ElasticBeanstalkEnvironmentDescription `json:"description"`
	Metadata      aws.Metadata                               `json:"metadata"`
	ResourceJobID int                                        `json:"resource_job_id"`
	SourceJobID   int                                        `json:"source_job_id"`
	ResourceType  string                                     `json:"resource_type"`
	SourceType    string                                     `json:"source_type"`
	ID            string                                     `json:"id"`
	SourceID      string                                     `json:"source_id"`
}

type ElasticBeanstalkEnvironmentHit struct {
	ID      string                      `json:"_id"`
	Score   float64                     `json:"_score"`
	Index   string                      `json:"_index"`
	Type    string                      `json:"_type"`
	Version int64                       `json:"_version,omitempty"`
	Source  ElasticBeanstalkEnvironment `json:"_source"`
	Sort    []interface{}               `json:"sort"`
}

type ElasticBeanstalkEnvironmentHits struct {
	Total SearchTotal                      `json:"total"`
	Hits  []ElasticBeanstalkEnvironmentHit `json:"hits"`
}

type ElasticBeanstalkEnvironmentSearchResponse struct {
	PitID string                          `json:"pit_id"`
	Hits  ElasticBeanstalkEnvironmentHits `json:"hits"`
}

type ElasticBeanstalkEnvironmentPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewElasticBeanstalkEnvironmentPaginator(filters []BoolFilter, limit *int64) (ElasticBeanstalkEnvironmentPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_elasticbeanstalk_environment", filters, limit)
	if err != nil {
		return ElasticBeanstalkEnvironmentPaginator{}, err
	}

	p := ElasticBeanstalkEnvironmentPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ElasticBeanstalkEnvironmentPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ElasticBeanstalkEnvironmentPaginator) NextPage(ctx context.Context) ([]ElasticBeanstalkEnvironment, error) {
	var response ElasticBeanstalkEnvironmentSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ElasticBeanstalkEnvironment
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listElasticBeanstalkEnvironmentFilters = map[string]string{}

func ListElasticBeanstalkEnvironment(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListElasticBeanstalkEnvironment")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewElasticBeanstalkEnvironmentPaginator(buildFilter(d.KeyColumnQuals, listElasticBeanstalkEnvironmentFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getElasticBeanstalkEnvironmentFilters = map[string]string{
	"environment_name": "description.EnvironmentDescription.EnvironmentName",
}

func GetElasticBeanstalkEnvironment(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetElasticBeanstalkEnvironment")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewElasticBeanstalkEnvironmentPaginator(buildFilter(d.KeyColumnQuals, getElasticBeanstalkEnvironmentFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ElasticBeanstalkEnvironment =============================

// ==========================  START: ElastiCacheReplicationGroup =============================

type ElastiCacheReplicationGroup struct {
	Description   aws.ElastiCacheReplicationGroupDescription `json:"description"`
	Metadata      aws.Metadata                               `json:"metadata"`
	ResourceJobID int                                        `json:"resource_job_id"`
	SourceJobID   int                                        `json:"source_job_id"`
	ResourceType  string                                     `json:"resource_type"`
	SourceType    string                                     `json:"source_type"`
	ID            string                                     `json:"id"`
	SourceID      string                                     `json:"source_id"`
}

type ElastiCacheReplicationGroupHit struct {
	ID      string                      `json:"_id"`
	Score   float64                     `json:"_score"`
	Index   string                      `json:"_index"`
	Type    string                      `json:"_type"`
	Version int64                       `json:"_version,omitempty"`
	Source  ElastiCacheReplicationGroup `json:"_source"`
	Sort    []interface{}               `json:"sort"`
}

type ElastiCacheReplicationGroupHits struct {
	Total SearchTotal                      `json:"total"`
	Hits  []ElastiCacheReplicationGroupHit `json:"hits"`
}

type ElastiCacheReplicationGroupSearchResponse struct {
	PitID string                          `json:"pit_id"`
	Hits  ElastiCacheReplicationGroupHits `json:"hits"`
}

type ElastiCacheReplicationGroupPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewElastiCacheReplicationGroupPaginator(filters []BoolFilter, limit *int64) (ElastiCacheReplicationGroupPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_elasticache_replicationgroup", filters, limit)
	if err != nil {
		return ElastiCacheReplicationGroupPaginator{}, err
	}

	p := ElastiCacheReplicationGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ElastiCacheReplicationGroupPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ElastiCacheReplicationGroupPaginator) NextPage(ctx context.Context) ([]ElastiCacheReplicationGroup, error) {
	var response ElastiCacheReplicationGroupSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ElastiCacheReplicationGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listElastiCacheReplicationGroupFilters = map[string]string{}

func ListElastiCacheReplicationGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListElastiCacheReplicationGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewElastiCacheReplicationGroupPaginator(buildFilter(d.KeyColumnQuals, listElastiCacheReplicationGroupFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getElastiCacheReplicationGroupFilters = map[string]string{
	"replication_group_id": "description.ReplicationGroup.ReplicationGroupId",
}

func GetElastiCacheReplicationGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetElastiCacheReplicationGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewElastiCacheReplicationGroupPaginator(buildFilter(d.KeyColumnQuals, getElastiCacheReplicationGroupFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ElastiCacheReplicationGroup =============================

// ==========================  START: ElastiCacheCluster =============================

type ElastiCacheCluster struct {
	Description   aws.ElastiCacheClusterDescription `json:"description"`
	Metadata      aws.Metadata                      `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	SourceID      string                            `json:"source_id"`
}

type ElastiCacheClusterHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  ElastiCacheCluster `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type ElastiCacheClusterHits struct {
	Total SearchTotal             `json:"total"`
	Hits  []ElastiCacheClusterHit `json:"hits"`
}

type ElastiCacheClusterSearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  ElastiCacheClusterHits `json:"hits"`
}

type ElastiCacheClusterPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewElastiCacheClusterPaginator(filters []BoolFilter, limit *int64) (ElastiCacheClusterPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_elasticache_cluster", filters, limit)
	if err != nil {
		return ElastiCacheClusterPaginator{}, err
	}

	p := ElastiCacheClusterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ElastiCacheClusterPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ElastiCacheClusterPaginator) NextPage(ctx context.Context) ([]ElastiCacheCluster, error) {
	var response ElastiCacheClusterSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ElastiCacheCluster
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listElastiCacheClusterFilters = map[string]string{}

func ListElastiCacheCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListElastiCacheCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewElastiCacheClusterPaginator(buildFilter(d.KeyColumnQuals, listElastiCacheClusterFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getElastiCacheClusterFilters = map[string]string{
	"cache_cluster_id": "description.Cluster.CacheClusterId",
}

func GetElastiCacheCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetElastiCacheCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewElastiCacheClusterPaginator(buildFilter(d.KeyColumnQuals, getElastiCacheClusterFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ElastiCacheCluster =============================

// ==========================  START: ESDomain =============================

type ESDomain struct {
	Description   aws.ESDomainDescription `json:"description"`
	Metadata      aws.Metadata            `json:"metadata"`
	ResourceJobID int                     `json:"resource_job_id"`
	SourceJobID   int                     `json:"source_job_id"`
	ResourceType  string                  `json:"resource_type"`
	SourceType    string                  `json:"source_type"`
	ID            string                  `json:"id"`
	SourceID      string                  `json:"source_id"`
}

type ESDomainHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  ESDomain      `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type ESDomainHits struct {
	Total SearchTotal   `json:"total"`
	Hits  []ESDomainHit `json:"hits"`
}

type ESDomainSearchResponse struct {
	PitID string       `json:"pit_id"`
	Hits  ESDomainHits `json:"hits"`
}

type ESDomainPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewESDomainPaginator(filters []BoolFilter, limit *int64) (ESDomainPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_elasticsearch_domain", filters, limit)
	if err != nil {
		return ESDomainPaginator{}, err
	}

	p := ESDomainPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ESDomainPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ESDomainPaginator) NextPage(ctx context.Context) ([]ESDomain, error) {
	var response ESDomainSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ESDomain
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listESDomainFilters = map[string]string{}

func ListESDomain(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListESDomain")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewESDomainPaginator(buildFilter(d.KeyColumnQuals, listESDomainFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getESDomainFilters = map[string]string{
	"domain_name": "description.Domain.DomainName",
}

func GetESDomain(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetESDomain")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewESDomainPaginator(buildFilter(d.KeyColumnQuals, getESDomainFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ESDomain =============================

// ==========================  START: EMRCluster =============================

type EMRCluster struct {
	Description   aws.EMRClusterDescription `json:"description"`
	Metadata      aws.Metadata              `json:"metadata"`
	ResourceJobID int                       `json:"resource_job_id"`
	SourceJobID   int                       `json:"source_job_id"`
	ResourceType  string                    `json:"resource_type"`
	SourceType    string                    `json:"source_type"`
	ID            string                    `json:"id"`
	SourceID      string                    `json:"source_id"`
}

type EMRClusterHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EMRCluster    `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EMRClusterHits struct {
	Total SearchTotal     `json:"total"`
	Hits  []EMRClusterHit `json:"hits"`
}

type EMRClusterSearchResponse struct {
	PitID string         `json:"pit_id"`
	Hits  EMRClusterHits `json:"hits"`
}

type EMRClusterPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEMRClusterPaginator(filters []BoolFilter, limit *int64) (EMRClusterPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_emr_cluster", filters, limit)
	if err != nil {
		return EMRClusterPaginator{}, err
	}

	p := EMRClusterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EMRClusterPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EMRClusterPaginator) NextPage(ctx context.Context) ([]EMRCluster, error) {
	var response EMRClusterSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EMRCluster
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEMRClusterFilters = map[string]string{}

func ListEMRCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEMRCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEMRClusterPaginator(buildFilter(d.KeyColumnQuals, listEMRClusterFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEMRClusterFilters = map[string]string{
	"id": "description.Cluster.Id",
}

func GetEMRCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEMRCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEMRClusterPaginator(buildFilter(d.KeyColumnQuals, getEMRClusterFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EMRCluster =============================

// ==========================  START: GuardDutyFinding =============================

type GuardDutyFinding struct {
	Description   aws.GuardDutyFindingDescription `json:"description"`
	Metadata      aws.Metadata                    `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	SourceID      string                          `json:"source_id"`
}

type GuardDutyFindingHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  GuardDutyFinding `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type GuardDutyFindingHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []GuardDutyFindingHit `json:"hits"`
}

type GuardDutyFindingSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  GuardDutyFindingHits `json:"hits"`
}

type GuardDutyFindingPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewGuardDutyFindingPaginator(filters []BoolFilter, limit *int64) (GuardDutyFindingPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_guardduty_finding", filters, limit)
	if err != nil {
		return GuardDutyFindingPaginator{}, err
	}

	p := GuardDutyFindingPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p GuardDutyFindingPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p GuardDutyFindingPaginator) NextPage(ctx context.Context) ([]GuardDutyFinding, error) {
	var response GuardDutyFindingSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []GuardDutyFinding
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listGuardDutyFindingFilters = map[string]string{}

func ListGuardDutyFinding(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListGuardDutyFinding")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewGuardDutyFindingPaginator(buildFilter(d.KeyColumnQuals, listGuardDutyFindingFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getGuardDutyFindingFilters = map[string]string{}

func GetGuardDutyFinding(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetGuardDutyFinding")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewGuardDutyFindingPaginator(buildFilter(d.KeyColumnQuals, getGuardDutyFindingFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: GuardDutyFinding =============================

// ==========================  START: GuardDutyDetector =============================

type GuardDutyDetector struct {
	Description   aws.GuardDutyDetectorDescription `json:"description"`
	Metadata      aws.Metadata                     `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	SourceID      string                           `json:"source_id"`
}

type GuardDutyDetectorHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  GuardDutyDetector `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type GuardDutyDetectorHits struct {
	Total SearchTotal            `json:"total"`
	Hits  []GuardDutyDetectorHit `json:"hits"`
}

type GuardDutyDetectorSearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  GuardDutyDetectorHits `json:"hits"`
}

type GuardDutyDetectorPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewGuardDutyDetectorPaginator(filters []BoolFilter, limit *int64) (GuardDutyDetectorPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_guardduty_detector", filters, limit)
	if err != nil {
		return GuardDutyDetectorPaginator{}, err
	}

	p := GuardDutyDetectorPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p GuardDutyDetectorPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p GuardDutyDetectorPaginator) NextPage(ctx context.Context) ([]GuardDutyDetector, error) {
	var response GuardDutyDetectorSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []GuardDutyDetector
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listGuardDutyDetectorFilters = map[string]string{}

func ListGuardDutyDetector(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListGuardDutyDetector")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewGuardDutyDetectorPaginator(buildFilter(d.KeyColumnQuals, listGuardDutyDetectorFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getGuardDutyDetectorFilters = map[string]string{
	"detector_id": "description.DetectorId",
}

func GetGuardDutyDetector(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetGuardDutyDetector")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewGuardDutyDetectorPaginator(buildFilter(d.KeyColumnQuals, getGuardDutyDetectorFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: GuardDutyDetector =============================

// ==========================  START: BackupPlan =============================

type BackupPlan struct {
	Description   aws.BackupPlanDescription `json:"description"`
	Metadata      aws.Metadata              `json:"metadata"`
	ResourceJobID int                       `json:"resource_job_id"`
	SourceJobID   int                       `json:"source_job_id"`
	ResourceType  string                    `json:"resource_type"`
	SourceType    string                    `json:"source_type"`
	ID            string                    `json:"id"`
	SourceID      string                    `json:"source_id"`
}

type BackupPlanHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  BackupPlan    `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type BackupPlanHits struct {
	Total SearchTotal     `json:"total"`
	Hits  []BackupPlanHit `json:"hits"`
}

type BackupPlanSearchResponse struct {
	PitID string         `json:"pit_id"`
	Hits  BackupPlanHits `json:"hits"`
}

type BackupPlanPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewBackupPlanPaginator(filters []BoolFilter, limit *int64) (BackupPlanPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_backup_plan", filters, limit)
	if err != nil {
		return BackupPlanPaginator{}, err
	}

	p := BackupPlanPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p BackupPlanPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p BackupPlanPaginator) NextPage(ctx context.Context) ([]BackupPlan, error) {
	var response BackupPlanSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []BackupPlan
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listBackupPlanFilters = map[string]string{}

func ListBackupPlan(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListBackupPlan")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewBackupPlanPaginator(buildFilter(d.KeyColumnQuals, listBackupPlanFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getBackupPlanFilters = map[string]string{
	"backup_plan_id": "description.BackupPlan.BackupPlanId",
}

func GetBackupPlan(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetBackupPlan")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewBackupPlanPaginator(buildFilter(d.KeyColumnQuals, getBackupPlanFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: BackupPlan =============================

// ==========================  START: BackupSelection =============================

type BackupSelection struct {
	Description   aws.BackupSelectionDescription `json:"description"`
	Metadata      aws.Metadata                   `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	SourceID      string                         `json:"source_id"`
}

type BackupSelectionHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  BackupSelection `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type BackupSelectionHits struct {
	Total SearchTotal          `json:"total"`
	Hits  []BackupSelectionHit `json:"hits"`
}

type BackupSelectionSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  BackupSelectionHits `json:"hits"`
}

type BackupSelectionPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewBackupSelectionPaginator(filters []BoolFilter, limit *int64) (BackupSelectionPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_backup_selection", filters, limit)
	if err != nil {
		return BackupSelectionPaginator{}, err
	}

	p := BackupSelectionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p BackupSelectionPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p BackupSelectionPaginator) NextPage(ctx context.Context) ([]BackupSelection, error) {
	var response BackupSelectionSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []BackupSelection
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listBackupSelectionFilters = map[string]string{}

func ListBackupSelection(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListBackupSelection")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewBackupSelectionPaginator(buildFilter(d.KeyColumnQuals, listBackupSelectionFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getBackupSelectionFilters = map[string]string{
	"backup_plan_id": "description.BackupSelection.BackupPlanId",
	"selection_id":   "description.BackupSelection.SelectionId",
}

func GetBackupSelection(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetBackupSelection")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewBackupSelectionPaginator(buildFilter(d.KeyColumnQuals, getBackupSelectionFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: BackupSelection =============================

// ==========================  START: BackupVault =============================

type BackupVault struct {
	Description   aws.BackupVaultDescription `json:"description"`
	Metadata      aws.Metadata               `json:"metadata"`
	ResourceJobID int                        `json:"resource_job_id"`
	SourceJobID   int                        `json:"source_job_id"`
	ResourceType  string                     `json:"resource_type"`
	SourceType    string                     `json:"source_type"`
	ID            string                     `json:"id"`
	SourceID      string                     `json:"source_id"`
}

type BackupVaultHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  BackupVault   `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type BackupVaultHits struct {
	Total SearchTotal      `json:"total"`
	Hits  []BackupVaultHit `json:"hits"`
}

type BackupVaultSearchResponse struct {
	PitID string          `json:"pit_id"`
	Hits  BackupVaultHits `json:"hits"`
}

type BackupVaultPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewBackupVaultPaginator(filters []BoolFilter, limit *int64) (BackupVaultPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_backup_vault", filters, limit)
	if err != nil {
		return BackupVaultPaginator{}, err
	}

	p := BackupVaultPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p BackupVaultPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p BackupVaultPaginator) NextPage(ctx context.Context) ([]BackupVault, error) {
	var response BackupVaultSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []BackupVault
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listBackupVaultFilters = map[string]string{}

func ListBackupVault(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListBackupVault")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewBackupVaultPaginator(buildFilter(d.KeyColumnQuals, listBackupVaultFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getBackupVaultFilters = map[string]string{
	"name": "description.BackupVault.BackupVaultName",
}

func GetBackupVault(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetBackupVault")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewBackupVaultPaginator(buildFilter(d.KeyColumnQuals, getBackupVaultFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: BackupVault =============================

// ==========================  START: BackupRecoveryPoint =============================

type BackupRecoveryPoint struct {
	Description   aws.BackupRecoveryPointDescription `json:"description"`
	Metadata      aws.Metadata                       `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	SourceID      string                             `json:"source_id"`
}

type BackupRecoveryPointHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  BackupRecoveryPoint `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type BackupRecoveryPointHits struct {
	Total SearchTotal              `json:"total"`
	Hits  []BackupRecoveryPointHit `json:"hits"`
}

type BackupRecoveryPointSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  BackupRecoveryPointHits `json:"hits"`
}

type BackupRecoveryPointPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewBackupRecoveryPointPaginator(filters []BoolFilter, limit *int64) (BackupRecoveryPointPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_backup_recoverypoint", filters, limit)
	if err != nil {
		return BackupRecoveryPointPaginator{}, err
	}

	p := BackupRecoveryPointPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p BackupRecoveryPointPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p BackupRecoveryPointPaginator) NextPage(ctx context.Context) ([]BackupRecoveryPoint, error) {
	var response BackupRecoveryPointSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []BackupRecoveryPoint
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listBackupRecoveryPointFilters = map[string]string{
	"completion_date":    "description.RecoveryPoint.CompletionDate",
	"recovery_point_arn": "description.RecoveryPoint.RecoveryPointArn",
	"resource_type":      "description.RecoveryPoint.ResourceType",
}

func ListBackupRecoveryPoint(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListBackupRecoveryPoint")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewBackupRecoveryPointPaginator(buildFilter(d.KeyColumnQuals, listBackupRecoveryPointFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getBackupRecoveryPointFilters = map[string]string{
	"backup_vault_name":  "description.RecoveryPoint.BackupVaultName",
	"recovery_point_arn": "description.RecoveryPoint.RecoveryPointArn",
}

func GetBackupRecoveryPoint(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetBackupRecoveryPoint")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewBackupRecoveryPointPaginator(buildFilter(d.KeyColumnQuals, getBackupRecoveryPointFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: BackupRecoveryPoint =============================

// ==========================  START: BackupProtectedResource =============================

type BackupProtectedResource struct {
	Description   aws.BackupProtectedResourceDescription `json:"description"`
	Metadata      aws.Metadata                           `json:"metadata"`
	ResourceJobID int                                    `json:"resource_job_id"`
	SourceJobID   int                                    `json:"source_job_id"`
	ResourceType  string                                 `json:"resource_type"`
	SourceType    string                                 `json:"source_type"`
	ID            string                                 `json:"id"`
	SourceID      string                                 `json:"source_id"`
}

type BackupProtectedResourceHit struct {
	ID      string                  `json:"_id"`
	Score   float64                 `json:"_score"`
	Index   string                  `json:"_index"`
	Type    string                  `json:"_type"`
	Version int64                   `json:"_version,omitempty"`
	Source  BackupProtectedResource `json:"_source"`
	Sort    []interface{}           `json:"sort"`
}

type BackupProtectedResourceHits struct {
	Total SearchTotal                  `json:"total"`
	Hits  []BackupProtectedResourceHit `json:"hits"`
}

type BackupProtectedResourceSearchResponse struct {
	PitID string                      `json:"pit_id"`
	Hits  BackupProtectedResourceHits `json:"hits"`
}

type BackupProtectedResourcePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewBackupProtectedResourcePaginator(filters []BoolFilter, limit *int64) (BackupProtectedResourcePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_backup_protectedresource", filters, limit)
	if err != nil {
		return BackupProtectedResourcePaginator{}, err
	}

	p := BackupProtectedResourcePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p BackupProtectedResourcePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p BackupProtectedResourcePaginator) NextPage(ctx context.Context) ([]BackupProtectedResource, error) {
	var response BackupProtectedResourceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []BackupProtectedResource
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listBackupProtectedResourceFilters = map[string]string{}

func ListBackupProtectedResource(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListBackupProtectedResource")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewBackupProtectedResourcePaginator(buildFilter(d.KeyColumnQuals, listBackupProtectedResourceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getBackupProtectedResourceFilters = map[string]string{
	"resource_arn": "description.ProtectedResource.ResourceArn",
}

func GetBackupProtectedResource(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetBackupProtectedResource")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewBackupProtectedResourcePaginator(buildFilter(d.KeyColumnQuals, getBackupProtectedResourceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: BackupProtectedResource =============================

// ==========================  START: CloudFrontDistribution =============================

type CloudFrontDistribution struct {
	Description   aws.CloudFrontDistributionDescription `json:"description"`
	Metadata      aws.Metadata                          `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	SourceID      string                                `json:"source_id"`
}

type CloudFrontDistributionHit struct {
	ID      string                 `json:"_id"`
	Score   float64                `json:"_score"`
	Index   string                 `json:"_index"`
	Type    string                 `json:"_type"`
	Version int64                  `json:"_version,omitempty"`
	Source  CloudFrontDistribution `json:"_source"`
	Sort    []interface{}          `json:"sort"`
}

type CloudFrontDistributionHits struct {
	Total SearchTotal                 `json:"total"`
	Hits  []CloudFrontDistributionHit `json:"hits"`
}

type CloudFrontDistributionSearchResponse struct {
	PitID string                     `json:"pit_id"`
	Hits  CloudFrontDistributionHits `json:"hits"`
}

type CloudFrontDistributionPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCloudFrontDistributionPaginator(filters []BoolFilter, limit *int64) (CloudFrontDistributionPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_cloudfront_distribution", filters, limit)
	if err != nil {
		return CloudFrontDistributionPaginator{}, err
	}

	p := CloudFrontDistributionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CloudFrontDistributionPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CloudFrontDistributionPaginator) NextPage(ctx context.Context) ([]CloudFrontDistribution, error) {
	var response CloudFrontDistributionSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CloudFrontDistribution
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCloudFrontDistributionFilters = map[string]string{}

func ListCloudFrontDistribution(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCloudFrontDistribution")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCloudFrontDistributionPaginator(buildFilter(d.KeyColumnQuals, listCloudFrontDistributionFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCloudFrontDistributionFilters = map[string]string{
	"id": "description.Distribution.Id",
}

func GetCloudFrontDistribution(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCloudFrontDistribution")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCloudFrontDistributionPaginator(buildFilter(d.KeyColumnQuals, getCloudFrontDistributionFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CloudFrontDistribution =============================

// ==========================  START: CloudWatchAlarm =============================

type CloudWatchAlarm struct {
	Description   aws.CloudWatchAlarmDescription `json:"description"`
	Metadata      aws.Metadata                   `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	SourceID      string                         `json:"source_id"`
}

type CloudWatchAlarmHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  CloudWatchAlarm `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type CloudWatchAlarmHits struct {
	Total SearchTotal          `json:"total"`
	Hits  []CloudWatchAlarmHit `json:"hits"`
}

type CloudWatchAlarmSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  CloudWatchAlarmHits `json:"hits"`
}

type CloudWatchAlarmPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCloudWatchAlarmPaginator(filters []BoolFilter, limit *int64) (CloudWatchAlarmPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_cloudwatch_alarm", filters, limit)
	if err != nil {
		return CloudWatchAlarmPaginator{}, err
	}

	p := CloudWatchAlarmPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CloudWatchAlarmPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CloudWatchAlarmPaginator) NextPage(ctx context.Context) ([]CloudWatchAlarm, error) {
	var response CloudWatchAlarmSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CloudWatchAlarm
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCloudWatchAlarmFilters = map[string]string{
	"name":        "description.MetricAlarm.AlarmName",
	"state_value": "description.MetricAlarm.StateValue",
}

func ListCloudWatchAlarm(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCloudWatchAlarm")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCloudWatchAlarmPaginator(buildFilter(d.KeyColumnQuals, listCloudWatchAlarmFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCloudWatchAlarmFilters = map[string]string{
	"name": "description.MetricAlarm.AlarmName",
}

func GetCloudWatchAlarm(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCloudWatchAlarm")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCloudWatchAlarmPaginator(buildFilter(d.KeyColumnQuals, getCloudWatchAlarmFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CloudWatchAlarm =============================

// ==========================  START: CloudWatchLogsLogGroup =============================

type CloudWatchLogsLogGroup struct {
	Description   aws.CloudWatchLogsLogGroupDescription `json:"description"`
	Metadata      aws.Metadata                          `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	SourceID      string                                `json:"source_id"`
}

type CloudWatchLogsLogGroupHit struct {
	ID      string                 `json:"_id"`
	Score   float64                `json:"_score"`
	Index   string                 `json:"_index"`
	Type    string                 `json:"_type"`
	Version int64                  `json:"_version,omitempty"`
	Source  CloudWatchLogsLogGroup `json:"_source"`
	Sort    []interface{}          `json:"sort"`
}

type CloudWatchLogsLogGroupHits struct {
	Total SearchTotal                 `json:"total"`
	Hits  []CloudWatchLogsLogGroupHit `json:"hits"`
}

type CloudWatchLogsLogGroupSearchResponse struct {
	PitID string                     `json:"pit_id"`
	Hits  CloudWatchLogsLogGroupHits `json:"hits"`
}

type CloudWatchLogsLogGroupPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCloudWatchLogsLogGroupPaginator(filters []BoolFilter, limit *int64) (CloudWatchLogsLogGroupPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_logs_loggroup", filters, limit)
	if err != nil {
		return CloudWatchLogsLogGroupPaginator{}, err
	}

	p := CloudWatchLogsLogGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CloudWatchLogsLogGroupPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CloudWatchLogsLogGroupPaginator) NextPage(ctx context.Context) ([]CloudWatchLogsLogGroup, error) {
	var response CloudWatchLogsLogGroupSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CloudWatchLogsLogGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCloudWatchLogsLogGroupFilters = map[string]string{
	"name": "description.LogGroup.LogGroupName",
}

func ListCloudWatchLogsLogGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCloudWatchLogsLogGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCloudWatchLogsLogGroupPaginator(buildFilter(d.KeyColumnQuals, listCloudWatchLogsLogGroupFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCloudWatchLogsLogGroupFilters = map[string]string{
	"name": "description.LogGroup.LogGroupName",
}

func GetCloudWatchLogsLogGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCloudWatchLogsLogGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCloudWatchLogsLogGroupPaginator(buildFilter(d.KeyColumnQuals, getCloudWatchLogsLogGroupFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CloudWatchLogsLogGroup =============================

// ==========================  START: CloudWatchLogsMetricFilter =============================

type CloudWatchLogsMetricFilter struct {
	Description   aws.CloudWatchLogsMetricFilterDescription `json:"description"`
	Metadata      aws.Metadata                              `json:"metadata"`
	ResourceJobID int                                       `json:"resource_job_id"`
	SourceJobID   int                                       `json:"source_job_id"`
	ResourceType  string                                    `json:"resource_type"`
	SourceType    string                                    `json:"source_type"`
	ID            string                                    `json:"id"`
	SourceID      string                                    `json:"source_id"`
}

type CloudWatchLogsMetricFilterHit struct {
	ID      string                     `json:"_id"`
	Score   float64                    `json:"_score"`
	Index   string                     `json:"_index"`
	Type    string                     `json:"_type"`
	Version int64                      `json:"_version,omitempty"`
	Source  CloudWatchLogsMetricFilter `json:"_source"`
	Sort    []interface{}              `json:"sort"`
}

type CloudWatchLogsMetricFilterHits struct {
	Total SearchTotal                     `json:"total"`
	Hits  []CloudWatchLogsMetricFilterHit `json:"hits"`
}

type CloudWatchLogsMetricFilterSearchResponse struct {
	PitID string                         `json:"pit_id"`
	Hits  CloudWatchLogsMetricFilterHits `json:"hits"`
}

type CloudWatchLogsMetricFilterPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCloudWatchLogsMetricFilterPaginator(filters []BoolFilter, limit *int64) (CloudWatchLogsMetricFilterPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_logs_metricfilter", filters, limit)
	if err != nil {
		return CloudWatchLogsMetricFilterPaginator{}, err
	}

	p := CloudWatchLogsMetricFilterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CloudWatchLogsMetricFilterPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CloudWatchLogsMetricFilterPaginator) NextPage(ctx context.Context) ([]CloudWatchLogsMetricFilter, error) {
	var response CloudWatchLogsMetricFilterSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CloudWatchLogsMetricFilter
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCloudWatchLogsMetricFilterFilters = map[string]string{
	"log_group_name":                  "decsription.MetricFilter.LogGroupName",
	"metric_transformation_name":      "decsription.MetricFilter.MetricTransformations.MetricName",
	"metric_transformation_namespace": "decsription.MetricFilter.MetricTransformations.MetricNamespace",
	"name":                            "decsription.MetricFilter.FilterName",
}

func ListCloudWatchLogsMetricFilter(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCloudWatchLogsMetricFilter")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCloudWatchLogsMetricFilterPaginator(buildFilter(d.KeyColumnQuals, listCloudWatchLogsMetricFilterFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCloudWatchLogsMetricFilterFilters = map[string]string{
	"name": "decsription.MetricFilter.FilterName",
}

func GetCloudWatchLogsMetricFilter(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCloudWatchLogsMetricFilter")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCloudWatchLogsMetricFilterPaginator(buildFilter(d.KeyColumnQuals, getCloudWatchLogsMetricFilterFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CloudWatchLogsMetricFilter =============================

// ==========================  START: CodeBuildProject =============================

type CodeBuildProject struct {
	Description   aws.CodeBuildProjectDescription `json:"description"`
	Metadata      aws.Metadata                    `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	SourceID      string                          `json:"source_id"`
}

type CodeBuildProjectHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  CodeBuildProject `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type CodeBuildProjectHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []CodeBuildProjectHit `json:"hits"`
}

type CodeBuildProjectSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  CodeBuildProjectHits `json:"hits"`
}

type CodeBuildProjectPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCodeBuildProjectPaginator(filters []BoolFilter, limit *int64) (CodeBuildProjectPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_codebuild_project", filters, limit)
	if err != nil {
		return CodeBuildProjectPaginator{}, err
	}

	p := CodeBuildProjectPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CodeBuildProjectPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CodeBuildProjectPaginator) NextPage(ctx context.Context) ([]CodeBuildProject, error) {
	var response CodeBuildProjectSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CodeBuildProject
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCodeBuildProjectFilters = map[string]string{}

func ListCodeBuildProject(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCodeBuildProject")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCodeBuildProjectPaginator(buildFilter(d.KeyColumnQuals, listCodeBuildProjectFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCodeBuildProjectFilters = map[string]string{
	"name": "description.Project.Name",
}

func GetCodeBuildProject(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCodeBuildProject")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCodeBuildProjectPaginator(buildFilter(d.KeyColumnQuals, getCodeBuildProjectFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CodeBuildProject =============================

// ==========================  START: CodeBuildSourceCredential =============================

type CodeBuildSourceCredential struct {
	Description   aws.CodeBuildSourceCredentialDescription `json:"description"`
	Metadata      aws.Metadata                             `json:"metadata"`
	ResourceJobID int                                      `json:"resource_job_id"`
	SourceJobID   int                                      `json:"source_job_id"`
	ResourceType  string                                   `json:"resource_type"`
	SourceType    string                                   `json:"source_type"`
	ID            string                                   `json:"id"`
	SourceID      string                                   `json:"source_id"`
}

type CodeBuildSourceCredentialHit struct {
	ID      string                    `json:"_id"`
	Score   float64                   `json:"_score"`
	Index   string                    `json:"_index"`
	Type    string                    `json:"_type"`
	Version int64                     `json:"_version,omitempty"`
	Source  CodeBuildSourceCredential `json:"_source"`
	Sort    []interface{}             `json:"sort"`
}

type CodeBuildSourceCredentialHits struct {
	Total SearchTotal                    `json:"total"`
	Hits  []CodeBuildSourceCredentialHit `json:"hits"`
}

type CodeBuildSourceCredentialSearchResponse struct {
	PitID string                        `json:"pit_id"`
	Hits  CodeBuildSourceCredentialHits `json:"hits"`
}

type CodeBuildSourceCredentialPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCodeBuildSourceCredentialPaginator(filters []BoolFilter, limit *int64) (CodeBuildSourceCredentialPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_codebuild_sourcecredential", filters, limit)
	if err != nil {
		return CodeBuildSourceCredentialPaginator{}, err
	}

	p := CodeBuildSourceCredentialPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CodeBuildSourceCredentialPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CodeBuildSourceCredentialPaginator) NextPage(ctx context.Context) ([]CodeBuildSourceCredential, error) {
	var response CodeBuildSourceCredentialSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CodeBuildSourceCredential
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCodeBuildSourceCredentialFilters = map[string]string{}

func ListCodeBuildSourceCredential(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCodeBuildSourceCredential")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCodeBuildSourceCredentialPaginator(buildFilter(d.KeyColumnQuals, listCodeBuildSourceCredentialFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCodeBuildSourceCredentialFilters = map[string]string{}

func GetCodeBuildSourceCredential(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCodeBuildSourceCredential")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCodeBuildSourceCredentialPaginator(buildFilter(d.KeyColumnQuals, getCodeBuildSourceCredentialFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CodeBuildSourceCredential =============================

// ==========================  START: ConfigConfigurationRecorder =============================

type ConfigConfigurationRecorder struct {
	Description   aws.ConfigConfigurationRecorderDescription `json:"description"`
	Metadata      aws.Metadata                               `json:"metadata"`
	ResourceJobID int                                        `json:"resource_job_id"`
	SourceJobID   int                                        `json:"source_job_id"`
	ResourceType  string                                     `json:"resource_type"`
	SourceType    string                                     `json:"source_type"`
	ID            string                                     `json:"id"`
	SourceID      string                                     `json:"source_id"`
}

type ConfigConfigurationRecorderHit struct {
	ID      string                      `json:"_id"`
	Score   float64                     `json:"_score"`
	Index   string                      `json:"_index"`
	Type    string                      `json:"_type"`
	Version int64                       `json:"_version,omitempty"`
	Source  ConfigConfigurationRecorder `json:"_source"`
	Sort    []interface{}               `json:"sort"`
}

type ConfigConfigurationRecorderHits struct {
	Total SearchTotal                      `json:"total"`
	Hits  []ConfigConfigurationRecorderHit `json:"hits"`
}

type ConfigConfigurationRecorderSearchResponse struct {
	PitID string                          `json:"pit_id"`
	Hits  ConfigConfigurationRecorderHits `json:"hits"`
}

type ConfigConfigurationRecorderPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewConfigConfigurationRecorderPaginator(filters []BoolFilter, limit *int64) (ConfigConfigurationRecorderPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_config_configurationrecorder", filters, limit)
	if err != nil {
		return ConfigConfigurationRecorderPaginator{}, err
	}

	p := ConfigConfigurationRecorderPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ConfigConfigurationRecorderPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ConfigConfigurationRecorderPaginator) NextPage(ctx context.Context) ([]ConfigConfigurationRecorder, error) {
	var response ConfigConfigurationRecorderSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ConfigConfigurationRecorder
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listConfigConfigurationRecorderFilters = map[string]string{
	"name": "description.ConfigurationRecorder.Name",
}

func ListConfigConfigurationRecorder(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListConfigConfigurationRecorder")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewConfigConfigurationRecorderPaginator(buildFilter(d.KeyColumnQuals, listConfigConfigurationRecorderFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getConfigConfigurationRecorderFilters = map[string]string{
	"name": "description.ConfigurationRecorder.Name",
}

func GetConfigConfigurationRecorder(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetConfigConfigurationRecorder")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewConfigConfigurationRecorderPaginator(buildFilter(d.KeyColumnQuals, getConfigConfigurationRecorderFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ConfigConfigurationRecorder =============================

// ==========================  START: DAXCluster =============================

type DAXCluster struct {
	Description   aws.DAXClusterDescription `json:"description"`
	Metadata      aws.Metadata              `json:"metadata"`
	ResourceJobID int                       `json:"resource_job_id"`
	SourceJobID   int                       `json:"source_job_id"`
	ResourceType  string                    `json:"resource_type"`
	SourceType    string                    `json:"source_type"`
	ID            string                    `json:"id"`
	SourceID      string                    `json:"source_id"`
}

type DAXClusterHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  DAXCluster    `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type DAXClusterHits struct {
	Total SearchTotal     `json:"total"`
	Hits  []DAXClusterHit `json:"hits"`
}

type DAXClusterSearchResponse struct {
	PitID string         `json:"pit_id"`
	Hits  DAXClusterHits `json:"hits"`
}

type DAXClusterPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDAXClusterPaginator(filters []BoolFilter, limit *int64) (DAXClusterPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_dax_cluster", filters, limit)
	if err != nil {
		return DAXClusterPaginator{}, err
	}

	p := DAXClusterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DAXClusterPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DAXClusterPaginator) NextPage(ctx context.Context) ([]DAXCluster, error) {
	var response DAXClusterSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DAXCluster
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDAXClusterFilters = map[string]string{
	"cluster_name": "description.Cluster.ClusterName",
}

func ListDAXCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDAXCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDAXClusterPaginator(buildFilter(d.KeyColumnQuals, listDAXClusterFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDAXClusterFilters = map[string]string{
	"cluster_name": "description.Cluster.ClusterName",
}

func GetDAXCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDAXCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDAXClusterPaginator(buildFilter(d.KeyColumnQuals, getDAXClusterFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DAXCluster =============================

// ==========================  START: DMSReplicationInstance =============================

type DMSReplicationInstance struct {
	Description   aws.DMSReplicationInstanceDescription `json:"description"`
	Metadata      aws.Metadata                          `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	SourceID      string                                `json:"source_id"`
}

type DMSReplicationInstanceHit struct {
	ID      string                 `json:"_id"`
	Score   float64                `json:"_score"`
	Index   string                 `json:"_index"`
	Type    string                 `json:"_type"`
	Version int64                  `json:"_version,omitempty"`
	Source  DMSReplicationInstance `json:"_source"`
	Sort    []interface{}          `json:"sort"`
}

type DMSReplicationInstanceHits struct {
	Total SearchTotal                 `json:"total"`
	Hits  []DMSReplicationInstanceHit `json:"hits"`
}

type DMSReplicationInstanceSearchResponse struct {
	PitID string                     `json:"pit_id"`
	Hits  DMSReplicationInstanceHits `json:"hits"`
}

type DMSReplicationInstancePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDMSReplicationInstancePaginator(filters []BoolFilter, limit *int64) (DMSReplicationInstancePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_dms_replicationinstance", filters, limit)
	if err != nil {
		return DMSReplicationInstancePaginator{}, err
	}

	p := DMSReplicationInstancePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DMSReplicationInstancePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DMSReplicationInstancePaginator) NextPage(ctx context.Context) ([]DMSReplicationInstance, error) {
	var response DMSReplicationInstanceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DMSReplicationInstance
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDMSReplicationInstanceFilters = map[string]string{
	"arn":                             "description.ReplicationInstance.ReplicationInstanceArn",
	"engine_version":                  "description.ReplicationInstance.EngineVersion",
	"replication_instance_class":      "description.ReplicationInstance.ReplicationInstanceClass",
	"replication_instance_identifier": "description.ReplicationInstance.ReplicationInstanceIdentifier",
}

func ListDMSReplicationInstance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDMSReplicationInstance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDMSReplicationInstancePaginator(buildFilter(d.KeyColumnQuals, listDMSReplicationInstanceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDMSReplicationInstanceFilters = map[string]string{
	"arn": "description.ReplicationInstance.ReplicationInstanceArn",
}

func GetDMSReplicationInstance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDMSReplicationInstance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDMSReplicationInstancePaginator(buildFilter(d.KeyColumnQuals, getDMSReplicationInstanceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DMSReplicationInstance =============================

// ==========================  START: DynamoDbTable =============================

type DynamoDbTable struct {
	Description   aws.DynamoDbTableDescription `json:"description"`
	Metadata      aws.Metadata                 `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	SourceID      string                       `json:"source_id"`
}

type DynamoDbTableHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  DynamoDbTable `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type DynamoDbTableHits struct {
	Total SearchTotal        `json:"total"`
	Hits  []DynamoDbTableHit `json:"hits"`
}

type DynamoDbTableSearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  DynamoDbTableHits `json:"hits"`
}

type DynamoDbTablePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDynamoDbTablePaginator(filters []BoolFilter, limit *int64) (DynamoDbTablePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_dynamodb_table", filters, limit)
	if err != nil {
		return DynamoDbTablePaginator{}, err
	}

	p := DynamoDbTablePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DynamoDbTablePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DynamoDbTablePaginator) NextPage(ctx context.Context) ([]DynamoDbTable, error) {
	var response DynamoDbTableSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DynamoDbTable
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDynamoDbTableFilters = map[string]string{
	"name": "description.Table.TableName",
}

func ListDynamoDbTable(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDynamoDbTable")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDynamoDbTablePaginator(buildFilter(d.KeyColumnQuals, listDynamoDbTableFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDynamoDbTableFilters = map[string]string{
	"name": "description.Table.TableName",
}

func GetDynamoDbTable(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDynamoDbTable")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDynamoDbTablePaginator(buildFilter(d.KeyColumnQuals, getDynamoDbTableFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DynamoDbTable =============================

// ==========================  START: EC2VolumeSnapshot =============================

type EC2VolumeSnapshot struct {
	Description   aws.EC2VolumeSnapshotDescription `json:"description"`
	Metadata      aws.Metadata                     `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	SourceID      string                           `json:"source_id"`
}

type EC2VolumeSnapshotHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  EC2VolumeSnapshot `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type EC2VolumeSnapshotHits struct {
	Total SearchTotal            `json:"total"`
	Hits  []EC2VolumeSnapshotHit `json:"hits"`
}

type EC2VolumeSnapshotSearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  EC2VolumeSnapshotHits `json:"hits"`
}

type EC2VolumeSnapshotPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2VolumeSnapshotPaginator(filters []BoolFilter, limit *int64) (EC2VolumeSnapshotPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_snapshot", filters, limit)
	if err != nil {
		return EC2VolumeSnapshotPaginator{}, err
	}

	p := EC2VolumeSnapshotPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2VolumeSnapshotPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2VolumeSnapshotPaginator) NextPage(ctx context.Context) ([]EC2VolumeSnapshot, error) {
	var response EC2VolumeSnapshotSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2VolumeSnapshot
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2VolumeSnapshotFilters = map[string]string{
	"description": "description.Snapshot.Description",
	"encrypted":   "description.Snapshot.Encrypted",
	"owner_alias": "description.Snapshot.OwnerAlias",
	"owner_id":    "description.Snapshot.OwnerId",
	"progress":    "description.Snapshot.Progress",
	"snapshot_id": "description.Snapshot.SnapshotId",
	"state":       "description.Snapshot.State",
	"volume_id":   "description.Snapshot.VolumeId",
	"volume_size": "description.Snapshot.VolumeSize",
}

func ListEC2VolumeSnapshot(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2VolumeSnapshot")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2VolumeSnapshotPaginator(buildFilter(d.KeyColumnQuals, listEC2VolumeSnapshotFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2VolumeSnapshotFilters = map[string]string{
	"snapshot_id": "description.Snapshot.SnapshotId",
}

func GetEC2VolumeSnapshot(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2VolumeSnapshot")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2VolumeSnapshotPaginator(buildFilter(d.KeyColumnQuals, getEC2VolumeSnapshotFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2VolumeSnapshot =============================

// ==========================  START: EC2Volume =============================

type EC2Volume struct {
	Description   aws.EC2VolumeDescription `json:"description"`
	Metadata      aws.Metadata             `json:"metadata"`
	ResourceJobID int                      `json:"resource_job_id"`
	SourceJobID   int                      `json:"source_job_id"`
	ResourceType  string                   `json:"resource_type"`
	SourceType    string                   `json:"source_type"`
	ID            string                   `json:"id"`
	SourceID      string                   `json:"source_id"`
}

type EC2VolumeHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EC2Volume     `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EC2VolumeHits struct {
	Total SearchTotal    `json:"total"`
	Hits  []EC2VolumeHit `json:"hits"`
}

type EC2VolumeSearchResponse struct {
	PitID string        `json:"pit_id"`
	Hits  EC2VolumeHits `json:"hits"`
}

type EC2VolumePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2VolumePaginator(filters []BoolFilter, limit *int64) (EC2VolumePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_volume", filters, limit)
	if err != nil {
		return EC2VolumePaginator{}, err
	}

	p := EC2VolumePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2VolumePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2VolumePaginator) NextPage(ctx context.Context) ([]EC2Volume, error) {
	var response EC2VolumeSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2Volume
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2VolumeFilters = map[string]string{}

func ListEC2Volume(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2Volume")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2VolumePaginator(buildFilter(d.KeyColumnQuals, listEC2VolumeFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2VolumeFilters = map[string]string{
	"volume_id": "description.Volume.VolumeId",
}

func GetEC2Volume(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2Volume")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2VolumePaginator(buildFilter(d.KeyColumnQuals, getEC2VolumeFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2Volume =============================

// ==========================  START: EC2Instance =============================

type EC2Instance struct {
	Description   aws.EC2InstanceDescription `json:"description"`
	Metadata      aws.Metadata               `json:"metadata"`
	ResourceJobID int                        `json:"resource_job_id"`
	SourceJobID   int                        `json:"source_job_id"`
	ResourceType  string                     `json:"resource_type"`
	SourceType    string                     `json:"source_type"`
	ID            string                     `json:"id"`
	SourceID      string                     `json:"source_id"`
}

type EC2InstanceHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EC2Instance   `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EC2InstanceHits struct {
	Total SearchTotal      `json:"total"`
	Hits  []EC2InstanceHit `json:"hits"`
}

type EC2InstanceSearchResponse struct {
	PitID string          `json:"pit_id"`
	Hits  EC2InstanceHits `json:"hits"`
}

type EC2InstancePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2InstancePaginator(filters []BoolFilter, limit *int64) (EC2InstancePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_instance", filters, limit)
	if err != nil {
		return EC2InstancePaginator{}, err
	}

	p := EC2InstancePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2InstancePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2InstancePaginator) NextPage(ctx context.Context) ([]EC2Instance, error) {
	var response EC2InstanceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2Instance
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2InstanceFilters = map[string]string{
	"hypervisor":                  "description.Instance.Hypervisor",
	"iam_instance_profile_arn":    "description.Instance.IamInstanceProfile.Arn",
	"image_id":                    "description.Instance.ImageId",
	"instance_lifecycle":          "description.Instance.InstanceLifecycle",
	"instance_state":              "description.Instance.State.Name",
	"instance_type":               "description.Instance.InstanceType",
	"monitoring_state":            "description.Instance.Monitoring.State",
	"outpost_arn":                 "description.Instance.OutpostArn",
	"placement_availability_zone": "description.Instance.Placement.AvailabilityZone",
	"placement_group_name":        "description.Instance.Placement.GroupName",
	"placement_tenancy":           "description.Instance.Placement.Tenancy",
	"public_dns_name":             "description.Instance.PublicDnsName",
	"ram_disk_id":                 "description.Instance.RamdiskId",
	"root_device_name":            "description.Instance.RootDeviceName",
	"root_device_type":            "description.Instance.RootDeviceType",
	"subnet_id":                   "description.Instance.SubnetId",
	"virtualization_type":         "description.Instance.VirtualizationType",
	"vpc_id":                      "description.Instance.VpcId",
}

func ListEC2Instance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2Instance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2InstancePaginator(buildFilter(d.KeyColumnQuals, listEC2InstanceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2InstanceFilters = map[string]string{
	"instance_id": "description.Instance.InstanceId",
}

func GetEC2Instance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2Instance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2InstancePaginator(buildFilter(d.KeyColumnQuals, getEC2InstanceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2Instance =============================

// ==========================  START: EC2Vpc =============================

type EC2Vpc struct {
	Description   aws.EC2VpcDescription `json:"description"`
	Metadata      aws.Metadata          `json:"metadata"`
	ResourceJobID int                   `json:"resource_job_id"`
	SourceJobID   int                   `json:"source_job_id"`
	ResourceType  string                `json:"resource_type"`
	SourceType    string                `json:"source_type"`
	ID            string                `json:"id"`
	SourceID      string                `json:"source_id"`
}

type EC2VpcHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EC2Vpc        `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EC2VpcHits struct {
	Total SearchTotal `json:"total"`
	Hits  []EC2VpcHit `json:"hits"`
}

type EC2VpcSearchResponse struct {
	PitID string     `json:"pit_id"`
	Hits  EC2VpcHits `json:"hits"`
}

type EC2VpcPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2VpcPaginator(filters []BoolFilter, limit *int64) (EC2VpcPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_vpc", filters, limit)
	if err != nil {
		return EC2VpcPaginator{}, err
	}

	p := EC2VpcPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2VpcPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2VpcPaginator) NextPage(ctx context.Context) ([]EC2Vpc, error) {
	var response EC2VpcSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2Vpc
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2VpcFilters = map[string]string{}

func ListEC2Vpc(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2Vpc")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2VpcPaginator(buildFilter(d.KeyColumnQuals, listEC2VpcFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2VpcFilters = map[string]string{
	"vpc_id": "description.Vpc.VpcId",
}

func GetEC2Vpc(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2Vpc")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2VpcPaginator(buildFilter(d.KeyColumnQuals, getEC2VpcFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2Vpc =============================

// ==========================  START: EC2NetworkInterface =============================

type EC2NetworkInterface struct {
	Description   aws.EC2NetworkInterfaceDescription `json:"description"`
	Metadata      aws.Metadata                       `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	SourceID      string                             `json:"source_id"`
}

type EC2NetworkInterfaceHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  EC2NetworkInterface `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type EC2NetworkInterfaceHits struct {
	Total SearchTotal              `json:"total"`
	Hits  []EC2NetworkInterfaceHit `json:"hits"`
}

type EC2NetworkInterfaceSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  EC2NetworkInterfaceHits `json:"hits"`
}

type EC2NetworkInterfacePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2NetworkInterfacePaginator(filters []BoolFilter, limit *int64) (EC2NetworkInterfacePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_networkinterface", filters, limit)
	if err != nil {
		return EC2NetworkInterfacePaginator{}, err
	}

	p := EC2NetworkInterfacePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2NetworkInterfacePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2NetworkInterfacePaginator) NextPage(ctx context.Context) ([]EC2NetworkInterface, error) {
	var response EC2NetworkInterfaceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2NetworkInterface
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2NetworkInterfaceFilters = map[string]string{}

func ListEC2NetworkInterface(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2NetworkInterface")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2NetworkInterfacePaginator(buildFilter(d.KeyColumnQuals, listEC2NetworkInterfaceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2NetworkInterfaceFilters = map[string]string{
	"network_interface_id": "description.NetworkInterface.NetworkInterfaceId",
}

func GetEC2NetworkInterface(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2NetworkInterface")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2NetworkInterfacePaginator(buildFilter(d.KeyColumnQuals, getEC2NetworkInterfaceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2NetworkInterface =============================

// ==========================  START: EC2RegionalSettings =============================

type EC2RegionalSettings struct {
	Description   aws.EC2RegionalSettingsDescription `json:"description"`
	Metadata      aws.Metadata                       `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	SourceID      string                             `json:"source_id"`
}

type EC2RegionalSettingsHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  EC2RegionalSettings `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type EC2RegionalSettingsHits struct {
	Total SearchTotal              `json:"total"`
	Hits  []EC2RegionalSettingsHit `json:"hits"`
}

type EC2RegionalSettingsSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  EC2RegionalSettingsHits `json:"hits"`
}

type EC2RegionalSettingsPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2RegionalSettingsPaginator(filters []BoolFilter, limit *int64) (EC2RegionalSettingsPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_regionalsettings", filters, limit)
	if err != nil {
		return EC2RegionalSettingsPaginator{}, err
	}

	p := EC2RegionalSettingsPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2RegionalSettingsPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2RegionalSettingsPaginator) NextPage(ctx context.Context) ([]EC2RegionalSettings, error) {
	var response EC2RegionalSettingsSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2RegionalSettings
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2RegionalSettingsFilters = map[string]string{}

func ListEC2RegionalSettings(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2RegionalSettings")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2RegionalSettingsPaginator(buildFilter(d.KeyColumnQuals, listEC2RegionalSettingsFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2RegionalSettingsFilters = map[string]string{}

func GetEC2RegionalSettings(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2RegionalSettings")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2RegionalSettingsPaginator(buildFilter(d.KeyColumnQuals, getEC2RegionalSettingsFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2RegionalSettings =============================

// ==========================  START: EC2Subnet =============================

type EC2Subnet struct {
	Description   aws.EC2SubnetDescription `json:"description"`
	Metadata      aws.Metadata             `json:"metadata"`
	ResourceJobID int                      `json:"resource_job_id"`
	SourceJobID   int                      `json:"source_job_id"`
	ResourceType  string                   `json:"resource_type"`
	SourceType    string                   `json:"source_type"`
	ID            string                   `json:"id"`
	SourceID      string                   `json:"source_id"`
}

type EC2SubnetHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EC2Subnet     `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EC2SubnetHits struct {
	Total SearchTotal    `json:"total"`
	Hits  []EC2SubnetHit `json:"hits"`
}

type EC2SubnetSearchResponse struct {
	PitID string        `json:"pit_id"`
	Hits  EC2SubnetHits `json:"hits"`
}

type EC2SubnetPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2SubnetPaginator(filters []BoolFilter, limit *int64) (EC2SubnetPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_subnet", filters, limit)
	if err != nil {
		return EC2SubnetPaginator{}, err
	}

	p := EC2SubnetPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2SubnetPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2SubnetPaginator) NextPage(ctx context.Context) ([]EC2Subnet, error) {
	var response EC2SubnetSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2Subnet
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2SubnetFilters = map[string]string{}

func ListEC2Subnet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2Subnet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2SubnetPaginator(buildFilter(d.KeyColumnQuals, listEC2SubnetFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2SubnetFilters = map[string]string{
	"subnet_id": "description.Subnet.SubnetId",
}

func GetEC2Subnet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2Subnet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2SubnetPaginator(buildFilter(d.KeyColumnQuals, getEC2SubnetFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2Subnet =============================

// ==========================  START: EC2VPCEndpoint =============================

type EC2VPCEndpoint struct {
	Description   aws.EC2VPCEndpointDescription `json:"description"`
	Metadata      aws.Metadata                  `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	SourceID      string                        `json:"source_id"`
}

type EC2VPCEndpointHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  EC2VPCEndpoint `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type EC2VPCEndpointHits struct {
	Total SearchTotal         `json:"total"`
	Hits  []EC2VPCEndpointHit `json:"hits"`
}

type EC2VPCEndpointSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  EC2VPCEndpointHits `json:"hits"`
}

type EC2VPCEndpointPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2VPCEndpointPaginator(filters []BoolFilter, limit *int64) (EC2VPCEndpointPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_vpcendpoint", filters, limit)
	if err != nil {
		return EC2VPCEndpointPaginator{}, err
	}

	p := EC2VPCEndpointPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2VPCEndpointPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2VPCEndpointPaginator) NextPage(ctx context.Context) ([]EC2VPCEndpoint, error) {
	var response EC2VPCEndpointSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2VPCEndpoint
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2VPCEndpointFilters = map[string]string{}

func ListEC2VPCEndpoint(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2VPCEndpoint")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2VPCEndpointPaginator(buildFilter(d.KeyColumnQuals, listEC2VPCEndpointFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2VPCEndpointFilters = map[string]string{
	"vpc_endpoint_id": "description.VpcEndpoint.VpcEndpointId",
}

func GetEC2VPCEndpoint(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2VPCEndpoint")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2VPCEndpointPaginator(buildFilter(d.KeyColumnQuals, getEC2VPCEndpointFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2VPCEndpoint =============================

// ==========================  START: EC2SecurityGroup =============================

type EC2SecurityGroup struct {
	Description   aws.EC2SecurityGroupDescription `json:"description"`
	Metadata      aws.Metadata                    `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	SourceID      string                          `json:"source_id"`
}

type EC2SecurityGroupHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  EC2SecurityGroup `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type EC2SecurityGroupHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []EC2SecurityGroupHit `json:"hits"`
}

type EC2SecurityGroupSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  EC2SecurityGroupHits `json:"hits"`
}

type EC2SecurityGroupPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2SecurityGroupPaginator(filters []BoolFilter, limit *int64) (EC2SecurityGroupPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_securitygroup", filters, limit)
	if err != nil {
		return EC2SecurityGroupPaginator{}, err
	}

	p := EC2SecurityGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2SecurityGroupPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2SecurityGroupPaginator) NextPage(ctx context.Context) ([]EC2SecurityGroup, error) {
	var response EC2SecurityGroupSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2SecurityGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2SecurityGroupFilters = map[string]string{}

func ListEC2SecurityGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2SecurityGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2SecurityGroupPaginator(buildFilter(d.KeyColumnQuals, listEC2SecurityGroupFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2SecurityGroupFilters = map[string]string{
	"group_id": "description.SecurityGroup.GroupId",
}

func GetEC2SecurityGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2SecurityGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2SecurityGroupPaginator(buildFilter(d.KeyColumnQuals, getEC2SecurityGroupFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2SecurityGroup =============================

// ==========================  START: EC2EIP =============================

type EC2EIP struct {
	Description   aws.EC2EIPDescription `json:"description"`
	Metadata      aws.Metadata          `json:"metadata"`
	ResourceJobID int                   `json:"resource_job_id"`
	SourceJobID   int                   `json:"source_job_id"`
	ResourceType  string                `json:"resource_type"`
	SourceType    string                `json:"source_type"`
	ID            string                `json:"id"`
	SourceID      string                `json:"source_id"`
}

type EC2EIPHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EC2EIP        `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EC2EIPHits struct {
	Total SearchTotal `json:"total"`
	Hits  []EC2EIPHit `json:"hits"`
}

type EC2EIPSearchResponse struct {
	PitID string     `json:"pit_id"`
	Hits  EC2EIPHits `json:"hits"`
}

type EC2EIPPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2EIPPaginator(filters []BoolFilter, limit *int64) (EC2EIPPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_eip", filters, limit)
	if err != nil {
		return EC2EIPPaginator{}, err
	}

	p := EC2EIPPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2EIPPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2EIPPaginator) NextPage(ctx context.Context) ([]EC2EIP, error) {
	var response EC2EIPSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2EIP
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2EIPFilters = map[string]string{}

func ListEC2EIP(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2EIP")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2EIPPaginator(buildFilter(d.KeyColumnQuals, listEC2EIPFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2EIPFilters = map[string]string{
	"allocation_id": "description.SecurityGroup.AllocationId",
}

func GetEC2EIP(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2EIP")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2EIPPaginator(buildFilter(d.KeyColumnQuals, getEC2EIPFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2EIP =============================

// ==========================  START: EC2InternetGateway =============================

type EC2InternetGateway struct {
	Description   aws.EC2InternetGatewayDescription `json:"description"`
	Metadata      aws.Metadata                      `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	SourceID      string                            `json:"source_id"`
}

type EC2InternetGatewayHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  EC2InternetGateway `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type EC2InternetGatewayHits struct {
	Total SearchTotal             `json:"total"`
	Hits  []EC2InternetGatewayHit `json:"hits"`
}

type EC2InternetGatewaySearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  EC2InternetGatewayHits `json:"hits"`
}

type EC2InternetGatewayPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2InternetGatewayPaginator(filters []BoolFilter, limit *int64) (EC2InternetGatewayPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_internetgateway", filters, limit)
	if err != nil {
		return EC2InternetGatewayPaginator{}, err
	}

	p := EC2InternetGatewayPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2InternetGatewayPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2InternetGatewayPaginator) NextPage(ctx context.Context) ([]EC2InternetGateway, error) {
	var response EC2InternetGatewaySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2InternetGateway
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2InternetGatewayFilters = map[string]string{}

func ListEC2InternetGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2InternetGateway")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2InternetGatewayPaginator(buildFilter(d.KeyColumnQuals, listEC2InternetGatewayFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2InternetGatewayFilters = map[string]string{
	"internet_gateway_id": "description.InternetGateway.InternetGatewayId",
}

func GetEC2InternetGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2InternetGateway")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2InternetGatewayPaginator(buildFilter(d.KeyColumnQuals, getEC2InternetGatewayFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2InternetGateway =============================

// ==========================  START: EC2NetworkAcl =============================

type EC2NetworkAcl struct {
	Description   aws.EC2NetworkAclDescription `json:"description"`
	Metadata      aws.Metadata                 `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	SourceID      string                       `json:"source_id"`
}

type EC2NetworkAclHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EC2NetworkAcl `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EC2NetworkAclHits struct {
	Total SearchTotal        `json:"total"`
	Hits  []EC2NetworkAclHit `json:"hits"`
}

type EC2NetworkAclSearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  EC2NetworkAclHits `json:"hits"`
}

type EC2NetworkAclPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2NetworkAclPaginator(filters []BoolFilter, limit *int64) (EC2NetworkAclPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_networkacl", filters, limit)
	if err != nil {
		return EC2NetworkAclPaginator{}, err
	}

	p := EC2NetworkAclPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2NetworkAclPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2NetworkAclPaginator) NextPage(ctx context.Context) ([]EC2NetworkAcl, error) {
	var response EC2NetworkAclSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2NetworkAcl
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2NetworkAclFilters = map[string]string{}

func ListEC2NetworkAcl(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2NetworkAcl")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2NetworkAclPaginator(buildFilter(d.KeyColumnQuals, listEC2NetworkAclFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2NetworkAclFilters = map[string]string{
	"network_acl_id": "description.NetworkAcl.NetworkAclId",
}

func GetEC2NetworkAcl(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2NetworkAcl")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2NetworkAclPaginator(buildFilter(d.KeyColumnQuals, getEC2NetworkAclFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2NetworkAcl =============================

// ==========================  START: EC2VPNConnection =============================

type EC2VPNConnection struct {
	Description   aws.EC2VPNConnectionDescription `json:"description"`
	Metadata      aws.Metadata                    `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	SourceID      string                          `json:"source_id"`
}

type EC2VPNConnectionHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  EC2VPNConnection `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type EC2VPNConnectionHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []EC2VPNConnectionHit `json:"hits"`
}

type EC2VPNConnectionSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  EC2VPNConnectionHits `json:"hits"`
}

type EC2VPNConnectionPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2VPNConnectionPaginator(filters []BoolFilter, limit *int64) (EC2VPNConnectionPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_vpnconnection", filters, limit)
	if err != nil {
		return EC2VPNConnectionPaginator{}, err
	}

	p := EC2VPNConnectionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2VPNConnectionPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2VPNConnectionPaginator) NextPage(ctx context.Context) ([]EC2VPNConnection, error) {
	var response EC2VPNConnectionSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2VPNConnection
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2VPNConnectionFilters = map[string]string{}

func ListEC2VPNConnection(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2VPNConnection")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2VPNConnectionPaginator(buildFilter(d.KeyColumnQuals, listEC2VPNConnectionFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2VPNConnectionFilters = map[string]string{
	"vpn_connection_id": "description.VpnConnection.VpnConnectionId",
}

func GetEC2VPNConnection(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2VPNConnection")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2VPNConnectionPaginator(buildFilter(d.KeyColumnQuals, getEC2VPNConnectionFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2VPNConnection =============================

// ==========================  START: EC2RouteTable =============================

type EC2RouteTable struct {
	Description   aws.EC2RouteTableDescription `json:"description"`
	Metadata      aws.Metadata                 `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	SourceID      string                       `json:"source_id"`
}

type EC2RouteTableHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EC2RouteTable `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EC2RouteTableHits struct {
	Total SearchTotal        `json:"total"`
	Hits  []EC2RouteTableHit `json:"hits"`
}

type EC2RouteTableSearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  EC2RouteTableHits `json:"hits"`
}

type EC2RouteTablePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2RouteTablePaginator(filters []BoolFilter, limit *int64) (EC2RouteTablePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_routetable", filters, limit)
	if err != nil {
		return EC2RouteTablePaginator{}, err
	}

	p := EC2RouteTablePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2RouteTablePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2RouteTablePaginator) NextPage(ctx context.Context) ([]EC2RouteTable, error) {
	var response EC2RouteTableSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2RouteTable
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2RouteTableFilters = map[string]string{}

func ListEC2RouteTable(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2RouteTable")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2RouteTablePaginator(buildFilter(d.KeyColumnQuals, listEC2RouteTableFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2RouteTableFilters = map[string]string{
	"route_table_id": "description.RouteTable.RouteTableId",
}

func GetEC2RouteTable(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2RouteTable")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2RouteTablePaginator(buildFilter(d.KeyColumnQuals, getEC2RouteTableFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2RouteTable =============================

// ==========================  START: EC2NatGateway =============================

type EC2NatGateway struct {
	Description   aws.EC2NatGatewayDescription `json:"description"`
	Metadata      aws.Metadata                 `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	SourceID      string                       `json:"source_id"`
}

type EC2NatGatewayHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EC2NatGateway `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EC2NatGatewayHits struct {
	Total SearchTotal        `json:"total"`
	Hits  []EC2NatGatewayHit `json:"hits"`
}

type EC2NatGatewaySearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  EC2NatGatewayHits `json:"hits"`
}

type EC2NatGatewayPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2NatGatewayPaginator(filters []BoolFilter, limit *int64) (EC2NatGatewayPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_natgateway", filters, limit)
	if err != nil {
		return EC2NatGatewayPaginator{}, err
	}

	p := EC2NatGatewayPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2NatGatewayPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2NatGatewayPaginator) NextPage(ctx context.Context) ([]EC2NatGateway, error) {
	var response EC2NatGatewaySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2NatGateway
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2NatGatewayFilters = map[string]string{}

func ListEC2NatGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2NatGateway")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2NatGatewayPaginator(buildFilter(d.KeyColumnQuals, listEC2NatGatewayFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2NatGatewayFilters = map[string]string{
	"nat_gateway_id": "description.NatGateway.NatGatewayId",
}

func GetEC2NatGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2NatGateway")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2NatGatewayPaginator(buildFilter(d.KeyColumnQuals, getEC2NatGatewayFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2NatGateway =============================

// ==========================  START: EC2Region =============================

type EC2Region struct {
	Description   aws.EC2RegionDescription `json:"description"`
	Metadata      aws.Metadata             `json:"metadata"`
	ResourceJobID int                      `json:"resource_job_id"`
	SourceJobID   int                      `json:"source_job_id"`
	ResourceType  string                   `json:"resource_type"`
	SourceType    string                   `json:"source_type"`
	ID            string                   `json:"id"`
	SourceID      string                   `json:"source_id"`
}

type EC2RegionHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EC2Region     `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EC2RegionHits struct {
	Total SearchTotal    `json:"total"`
	Hits  []EC2RegionHit `json:"hits"`
}

type EC2RegionSearchResponse struct {
	PitID string        `json:"pit_id"`
	Hits  EC2RegionHits `json:"hits"`
}

type EC2RegionPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2RegionPaginator(filters []BoolFilter, limit *int64) (EC2RegionPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_region", filters, limit)
	if err != nil {
		return EC2RegionPaginator{}, err
	}

	p := EC2RegionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2RegionPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2RegionPaginator) NextPage(ctx context.Context) ([]EC2Region, error) {
	var response EC2RegionSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2Region
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2RegionFilters = map[string]string{}

func ListEC2Region(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2Region")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2RegionPaginator(buildFilter(d.KeyColumnQuals, listEC2RegionFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2RegionFilters = map[string]string{
	"name": "description.Region.RegionName",
}

func GetEC2Region(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2Region")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2RegionPaginator(buildFilter(d.KeyColumnQuals, getEC2RegionFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2Region =============================

// ==========================  START: EC2FlowLog =============================

type EC2FlowLog struct {
	Description   aws.EC2FlowLogDescription `json:"description"`
	Metadata      aws.Metadata              `json:"metadata"`
	ResourceJobID int                       `json:"resource_job_id"`
	SourceJobID   int                       `json:"source_job_id"`
	ResourceType  string                    `json:"resource_type"`
	SourceType    string                    `json:"source_type"`
	ID            string                    `json:"id"`
	SourceID      string                    `json:"source_id"`
}

type EC2FlowLogHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EC2FlowLog    `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EC2FlowLogHits struct {
	Total SearchTotal     `json:"total"`
	Hits  []EC2FlowLogHit `json:"hits"`
}

type EC2FlowLogSearchResponse struct {
	PitID string         `json:"pit_id"`
	Hits  EC2FlowLogHits `json:"hits"`
}

type EC2FlowLogPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2FlowLogPaginator(filters []BoolFilter, limit *int64) (EC2FlowLogPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_flowlog", filters, limit)
	if err != nil {
		return EC2FlowLogPaginator{}, err
	}

	p := EC2FlowLogPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2FlowLogPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2FlowLogPaginator) NextPage(ctx context.Context) ([]EC2FlowLog, error) {
	var response EC2FlowLogSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2FlowLog
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2FlowLogFilters = map[string]string{}

func ListEC2FlowLog(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2FlowLog")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2FlowLogPaginator(buildFilter(d.KeyColumnQuals, listEC2FlowLogFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2FlowLogFilters = map[string]string{
	"flow_log_id": "description.FlowLog.FlowLogId",
}

func GetEC2FlowLog(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2FlowLog")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2FlowLogPaginator(buildFilter(d.KeyColumnQuals, getEC2FlowLogFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2FlowLog =============================

// ==========================  START: EC2CapacityReservation =============================

type EC2CapacityReservation struct {
	Description   aws.EC2CapacityReservationDescription `json:"description"`
	Metadata      aws.Metadata                          `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	SourceID      string                                `json:"source_id"`
}

type EC2CapacityReservationHit struct {
	ID      string                 `json:"_id"`
	Score   float64                `json:"_score"`
	Index   string                 `json:"_index"`
	Type    string                 `json:"_type"`
	Version int64                  `json:"_version,omitempty"`
	Source  EC2CapacityReservation `json:"_source"`
	Sort    []interface{}          `json:"sort"`
}

type EC2CapacityReservationHits struct {
	Total SearchTotal                 `json:"total"`
	Hits  []EC2CapacityReservationHit `json:"hits"`
}

type EC2CapacityReservationSearchResponse struct {
	PitID string                     `json:"pit_id"`
	Hits  EC2CapacityReservationHits `json:"hits"`
}

type EC2CapacityReservationPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2CapacityReservationPaginator(filters []BoolFilter, limit *int64) (EC2CapacityReservationPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_capacityreservation", filters, limit)
	if err != nil {
		return EC2CapacityReservationPaginator{}, err
	}

	p := EC2CapacityReservationPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2CapacityReservationPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2CapacityReservationPaginator) NextPage(ctx context.Context) ([]EC2CapacityReservation, error) {
	var response EC2CapacityReservationSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2CapacityReservation
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2CapacityReservationFilters = map[string]string{}

func ListEC2CapacityReservation(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2CapacityReservation")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2CapacityReservationPaginator(buildFilter(d.KeyColumnQuals, listEC2CapacityReservationFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2CapacityReservationFilters = map[string]string{
	"capacity_reservation_id": "description.CapacityReservation.CapacityReservationId",
}

func GetEC2CapacityReservation(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2CapacityReservation")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2CapacityReservationPaginator(buildFilter(d.KeyColumnQuals, getEC2CapacityReservationFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2CapacityReservation =============================

// ==========================  START: EC2KeyPair =============================

type EC2KeyPair struct {
	Description   aws.EC2KeyPairDescription `json:"description"`
	Metadata      aws.Metadata              `json:"metadata"`
	ResourceJobID int                       `json:"resource_job_id"`
	SourceJobID   int                       `json:"source_job_id"`
	ResourceType  string                    `json:"resource_type"`
	SourceType    string                    `json:"source_type"`
	ID            string                    `json:"id"`
	SourceID      string                    `json:"source_id"`
}

type EC2KeyPairHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EC2KeyPair    `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EC2KeyPairHits struct {
	Total SearchTotal     `json:"total"`
	Hits  []EC2KeyPairHit `json:"hits"`
}

type EC2KeyPairSearchResponse struct {
	PitID string         `json:"pit_id"`
	Hits  EC2KeyPairHits `json:"hits"`
}

type EC2KeyPairPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2KeyPairPaginator(filters []BoolFilter, limit *int64) (EC2KeyPairPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_keypair", filters, limit)
	if err != nil {
		return EC2KeyPairPaginator{}, err
	}

	p := EC2KeyPairPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2KeyPairPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2KeyPairPaginator) NextPage(ctx context.Context) ([]EC2KeyPair, error) {
	var response EC2KeyPairSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2KeyPair
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2KeyPairFilters = map[string]string{}

func ListEC2KeyPair(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2KeyPair")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2KeyPairPaginator(buildFilter(d.KeyColumnQuals, listEC2KeyPairFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2KeyPairFilters = map[string]string{
	"key_name": "description.KeyPair.KeyName",
}

func GetEC2KeyPair(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2KeyPair")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2KeyPairPaginator(buildFilter(d.KeyColumnQuals, getEC2KeyPairFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2KeyPair =============================

// ==========================  START: EC2AMI =============================

type EC2AMI struct {
	Description   aws.EC2AMIDescription `json:"description"`
	Metadata      aws.Metadata          `json:"metadata"`
	ResourceJobID int                   `json:"resource_job_id"`
	SourceJobID   int                   `json:"source_job_id"`
	ResourceType  string                `json:"resource_type"`
	SourceType    string                `json:"source_type"`
	ID            string                `json:"id"`
	SourceID      string                `json:"source_id"`
}

type EC2AMIHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EC2AMI        `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EC2AMIHits struct {
	Total SearchTotal `json:"total"`
	Hits  []EC2AMIHit `json:"hits"`
}

type EC2AMISearchResponse struct {
	PitID string     `json:"pit_id"`
	Hits  EC2AMIHits `json:"hits"`
}

type EC2AMIPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2AMIPaginator(filters []BoolFilter, limit *int64) (EC2AMIPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_ami", filters, limit)
	if err != nil {
		return EC2AMIPaginator{}, err
	}

	p := EC2AMIPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2AMIPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2AMIPaginator) NextPage(ctx context.Context) ([]EC2AMI, error) {
	var response EC2AMISearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2AMI
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2AMIFilters = map[string]string{}

func ListEC2AMI(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2AMI")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2AMIPaginator(buildFilter(d.KeyColumnQuals, listEC2AMIFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2AMIFilters = map[string]string{
	"image_id": "description.AMI.ImageId",
}

func GetEC2AMI(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2AMI")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2AMIPaginator(buildFilter(d.KeyColumnQuals, getEC2AMIFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2AMI =============================

// ==========================  START: EC2ReservedInstances =============================

type EC2ReservedInstances struct {
	Description   aws.EC2ReservedInstancesDescription `json:"description"`
	Metadata      aws.Metadata                        `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	SourceID      string                              `json:"source_id"`
}

type EC2ReservedInstancesHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  EC2ReservedInstances `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type EC2ReservedInstancesHits struct {
	Total SearchTotal               `json:"total"`
	Hits  []EC2ReservedInstancesHit `json:"hits"`
}

type EC2ReservedInstancesSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  EC2ReservedInstancesHits `json:"hits"`
}

type EC2ReservedInstancesPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2ReservedInstancesPaginator(filters []BoolFilter, limit *int64) (EC2ReservedInstancesPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_reservedinstance", filters, limit)
	if err != nil {
		return EC2ReservedInstancesPaginator{}, err
	}

	p := EC2ReservedInstancesPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2ReservedInstancesPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2ReservedInstancesPaginator) NextPage(ctx context.Context) ([]EC2ReservedInstances, error) {
	var response EC2ReservedInstancesSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2ReservedInstances
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2ReservedInstancesFilters = map[string]string{}

func ListEC2ReservedInstances(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2ReservedInstances")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2ReservedInstancesPaginator(buildFilter(d.KeyColumnQuals, listEC2ReservedInstancesFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2ReservedInstancesFilters = map[string]string{
	"reserved_instance_id": "description.ReservedInstance.ReservedInstancesId",
}

func GetEC2ReservedInstances(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2ReservedInstances")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2ReservedInstancesPaginator(buildFilter(d.KeyColumnQuals, getEC2ReservedInstancesFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2ReservedInstances =============================

// ==========================  START: EC2CapacityReservationFleet =============================

type EC2CapacityReservationFleet struct {
	Description   aws.EC2CapacityReservationFleetDescription `json:"description"`
	Metadata      aws.Metadata                               `json:"metadata"`
	ResourceJobID int                                        `json:"resource_job_id"`
	SourceJobID   int                                        `json:"source_job_id"`
	ResourceType  string                                     `json:"resource_type"`
	SourceType    string                                     `json:"source_type"`
	ID            string                                     `json:"id"`
	SourceID      string                                     `json:"source_id"`
}

type EC2CapacityReservationFleetHit struct {
	ID      string                      `json:"_id"`
	Score   float64                     `json:"_score"`
	Index   string                      `json:"_index"`
	Type    string                      `json:"_type"`
	Version int64                       `json:"_version,omitempty"`
	Source  EC2CapacityReservationFleet `json:"_source"`
	Sort    []interface{}               `json:"sort"`
}

type EC2CapacityReservationFleetHits struct {
	Total SearchTotal                      `json:"total"`
	Hits  []EC2CapacityReservationFleetHit `json:"hits"`
}

type EC2CapacityReservationFleetSearchResponse struct {
	PitID string                          `json:"pit_id"`
	Hits  EC2CapacityReservationFleetHits `json:"hits"`
}

type EC2CapacityReservationFleetPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2CapacityReservationFleetPaginator(filters []BoolFilter, limit *int64) (EC2CapacityReservationFleetPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_capacityreservationfleet", filters, limit)
	if err != nil {
		return EC2CapacityReservationFleetPaginator{}, err
	}

	p := EC2CapacityReservationFleetPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2CapacityReservationFleetPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2CapacityReservationFleetPaginator) NextPage(ctx context.Context) ([]EC2CapacityReservationFleet, error) {
	var response EC2CapacityReservationFleetSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2CapacityReservationFleet
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2CapacityReservationFleetFilters = map[string]string{}

func ListEC2CapacityReservationFleet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2CapacityReservationFleet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2CapacityReservationFleetPaginator(buildFilter(d.KeyColumnQuals, listEC2CapacityReservationFleetFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2CapacityReservationFleetFilters = map[string]string{
	"capacity_reservation_fleet_id": "description.CapacityReservationFleet.CapacityReservationFleetId",
}

func GetEC2CapacityReservationFleet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2CapacityReservationFleet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2CapacityReservationFleetPaginator(buildFilter(d.KeyColumnQuals, getEC2CapacityReservationFleetFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2CapacityReservationFleet =============================

// ==========================  START: EC2Fleet =============================

type EC2Fleet struct {
	Description   aws.EC2FleetDescription `json:"description"`
	Metadata      aws.Metadata            `json:"metadata"`
	ResourceJobID int                     `json:"resource_job_id"`
	SourceJobID   int                     `json:"source_job_id"`
	ResourceType  string                  `json:"resource_type"`
	SourceType    string                  `json:"source_type"`
	ID            string                  `json:"id"`
	SourceID      string                  `json:"source_id"`
}

type EC2FleetHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EC2Fleet      `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EC2FleetHits struct {
	Total SearchTotal   `json:"total"`
	Hits  []EC2FleetHit `json:"hits"`
}

type EC2FleetSearchResponse struct {
	PitID string       `json:"pit_id"`
	Hits  EC2FleetHits `json:"hits"`
}

type EC2FleetPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2FleetPaginator(filters []BoolFilter, limit *int64) (EC2FleetPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_fleet", filters, limit)
	if err != nil {
		return EC2FleetPaginator{}, err
	}

	p := EC2FleetPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2FleetPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2FleetPaginator) NextPage(ctx context.Context) ([]EC2Fleet, error) {
	var response EC2FleetSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2Fleet
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2FleetFilters = map[string]string{}

func ListEC2Fleet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2Fleet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2FleetPaginator(buildFilter(d.KeyColumnQuals, listEC2FleetFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2FleetFilters = map[string]string{
	"fleet_id": "description.Fleet.FleetId",
}

func GetEC2Fleet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2Fleet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2FleetPaginator(buildFilter(d.KeyColumnQuals, getEC2FleetFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2Fleet =============================

// ==========================  START: EC2Host =============================

type EC2Host struct {
	Description   aws.EC2HostDescription `json:"description"`
	Metadata      aws.Metadata           `json:"metadata"`
	ResourceJobID int                    `json:"resource_job_id"`
	SourceJobID   int                    `json:"source_job_id"`
	ResourceType  string                 `json:"resource_type"`
	SourceType    string                 `json:"source_type"`
	ID            string                 `json:"id"`
	SourceID      string                 `json:"source_id"`
}

type EC2HostHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EC2Host       `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EC2HostHits struct {
	Total SearchTotal  `json:"total"`
	Hits  []EC2HostHit `json:"hits"`
}

type EC2HostSearchResponse struct {
	PitID string      `json:"pit_id"`
	Hits  EC2HostHits `json:"hits"`
}

type EC2HostPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2HostPaginator(filters []BoolFilter, limit *int64) (EC2HostPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_host", filters, limit)
	if err != nil {
		return EC2HostPaginator{}, err
	}

	p := EC2HostPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2HostPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2HostPaginator) NextPage(ctx context.Context) ([]EC2Host, error) {
	var response EC2HostSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2Host
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2HostFilters = map[string]string{}

func ListEC2Host(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2Host")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2HostPaginator(buildFilter(d.KeyColumnQuals, listEC2HostFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2HostFilters = map[string]string{
	"host_id": "description.Host.HostId",
}

func GetEC2Host(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2Host")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2HostPaginator(buildFilter(d.KeyColumnQuals, getEC2HostFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2Host =============================

// ==========================  START: EC2PlacementGroup =============================

type EC2PlacementGroup struct {
	Description   aws.EC2PlacementGroupDescription `json:"description"`
	Metadata      aws.Metadata                     `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	SourceID      string                           `json:"source_id"`
}

type EC2PlacementGroupHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  EC2PlacementGroup `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type EC2PlacementGroupHits struct {
	Total SearchTotal            `json:"total"`
	Hits  []EC2PlacementGroupHit `json:"hits"`
}

type EC2PlacementGroupSearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  EC2PlacementGroupHits `json:"hits"`
}

type EC2PlacementGroupPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEC2PlacementGroupPaginator(filters []BoolFilter, limit *int64) (EC2PlacementGroupPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ec2_placementgroup", filters, limit)
	if err != nil {
		return EC2PlacementGroupPaginator{}, err
	}

	p := EC2PlacementGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EC2PlacementGroupPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EC2PlacementGroupPaginator) NextPage(ctx context.Context) ([]EC2PlacementGroup, error) {
	var response EC2PlacementGroupSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EC2PlacementGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEC2PlacementGroupFilters = map[string]string{}

func ListEC2PlacementGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEC2PlacementGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEC2PlacementGroupPaginator(buildFilter(d.KeyColumnQuals, listEC2PlacementGroupFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEC2PlacementGroupFilters = map[string]string{
	"group_name": "description.PlacementGroup.GroupName",
}

func GetEC2PlacementGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEC2PlacementGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEC2PlacementGroupPaginator(buildFilter(d.KeyColumnQuals, getEC2PlacementGroupFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EC2PlacementGroup =============================

// ==========================  START: ElasticLoadBalancingV2LoadBalancer =============================

type ElasticLoadBalancingV2LoadBalancer struct {
	Description   aws.ElasticLoadBalancingV2LoadBalancerDescription `json:"description"`
	Metadata      aws.Metadata                                      `json:"metadata"`
	ResourceJobID int                                               `json:"resource_job_id"`
	SourceJobID   int                                               `json:"source_job_id"`
	ResourceType  string                                            `json:"resource_type"`
	SourceType    string                                            `json:"source_type"`
	ID            string                                            `json:"id"`
	SourceID      string                                            `json:"source_id"`
}

type ElasticLoadBalancingV2LoadBalancerHit struct {
	ID      string                             `json:"_id"`
	Score   float64                            `json:"_score"`
	Index   string                             `json:"_index"`
	Type    string                             `json:"_type"`
	Version int64                              `json:"_version,omitempty"`
	Source  ElasticLoadBalancingV2LoadBalancer `json:"_source"`
	Sort    []interface{}                      `json:"sort"`
}

type ElasticLoadBalancingV2LoadBalancerHits struct {
	Total SearchTotal                             `json:"total"`
	Hits  []ElasticLoadBalancingV2LoadBalancerHit `json:"hits"`
}

type ElasticLoadBalancingV2LoadBalancerSearchResponse struct {
	PitID string                                 `json:"pit_id"`
	Hits  ElasticLoadBalancingV2LoadBalancerHits `json:"hits"`
}

type ElasticLoadBalancingV2LoadBalancerPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewElasticLoadBalancingV2LoadBalancerPaginator(filters []BoolFilter, limit *int64) (ElasticLoadBalancingV2LoadBalancerPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_elasticloadbalancingv2_loadbalancer", filters, limit)
	if err != nil {
		return ElasticLoadBalancingV2LoadBalancerPaginator{}, err
	}

	p := ElasticLoadBalancingV2LoadBalancerPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ElasticLoadBalancingV2LoadBalancerPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ElasticLoadBalancingV2LoadBalancerPaginator) NextPage(ctx context.Context) ([]ElasticLoadBalancingV2LoadBalancer, error) {
	var response ElasticLoadBalancingV2LoadBalancerSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ElasticLoadBalancingV2LoadBalancer
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listElasticLoadBalancingV2LoadBalancerFilters = map[string]string{
	"type": "description.LoadBalancer.Type",
}

func ListElasticLoadBalancingV2LoadBalancer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListElasticLoadBalancingV2LoadBalancer")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewElasticLoadBalancingV2LoadBalancerPaginator(buildFilter(d.KeyColumnQuals, listElasticLoadBalancingV2LoadBalancerFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getElasticLoadBalancingV2LoadBalancerFilters = map[string]string{
	"arn":  "description.LoadBalancer.LoadBalancerArn",
	"type": "description.LoadBalancer.Type",
}

func GetElasticLoadBalancingV2LoadBalancer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetElasticLoadBalancingV2LoadBalancer")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewElasticLoadBalancingV2LoadBalancerPaginator(buildFilter(d.KeyColumnQuals, getElasticLoadBalancingV2LoadBalancerFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ElasticLoadBalancingV2LoadBalancer =============================

// ==========================  START: ElasticLoadBalancingLoadBalancer =============================

type ElasticLoadBalancingLoadBalancer struct {
	Description   aws.ElasticLoadBalancingLoadBalancerDescription `json:"description"`
	Metadata      aws.Metadata                                    `json:"metadata"`
	ResourceJobID int                                             `json:"resource_job_id"`
	SourceJobID   int                                             `json:"source_job_id"`
	ResourceType  string                                          `json:"resource_type"`
	SourceType    string                                          `json:"source_type"`
	ID            string                                          `json:"id"`
	SourceID      string                                          `json:"source_id"`
}

type ElasticLoadBalancingLoadBalancerHit struct {
	ID      string                           `json:"_id"`
	Score   float64                          `json:"_score"`
	Index   string                           `json:"_index"`
	Type    string                           `json:"_type"`
	Version int64                            `json:"_version,omitempty"`
	Source  ElasticLoadBalancingLoadBalancer `json:"_source"`
	Sort    []interface{}                    `json:"sort"`
}

type ElasticLoadBalancingLoadBalancerHits struct {
	Total SearchTotal                           `json:"total"`
	Hits  []ElasticLoadBalancingLoadBalancerHit `json:"hits"`
}

type ElasticLoadBalancingLoadBalancerSearchResponse struct {
	PitID string                               `json:"pit_id"`
	Hits  ElasticLoadBalancingLoadBalancerHits `json:"hits"`
}

type ElasticLoadBalancingLoadBalancerPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewElasticLoadBalancingLoadBalancerPaginator(filters []BoolFilter, limit *int64) (ElasticLoadBalancingLoadBalancerPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_elasticloadbalancing_loadbalancer", filters, limit)
	if err != nil {
		return ElasticLoadBalancingLoadBalancerPaginator{}, err
	}

	p := ElasticLoadBalancingLoadBalancerPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ElasticLoadBalancingLoadBalancerPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ElasticLoadBalancingLoadBalancerPaginator) NextPage(ctx context.Context) ([]ElasticLoadBalancingLoadBalancer, error) {
	var response ElasticLoadBalancingLoadBalancerSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ElasticLoadBalancingLoadBalancer
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listElasticLoadBalancingLoadBalancerFilters = map[string]string{}

func ListElasticLoadBalancingLoadBalancer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListElasticLoadBalancingLoadBalancer")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewElasticLoadBalancingLoadBalancerPaginator(buildFilter(d.KeyColumnQuals, listElasticLoadBalancingLoadBalancerFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getElasticLoadBalancingLoadBalancerFilters = map[string]string{
	"name": "description.LoadBalancer.LoadBalancerName",
}

func GetElasticLoadBalancingLoadBalancer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetElasticLoadBalancingLoadBalancer")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewElasticLoadBalancingLoadBalancerPaginator(buildFilter(d.KeyColumnQuals, getElasticLoadBalancingLoadBalancerFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ElasticLoadBalancingLoadBalancer =============================

// ==========================  START: ElasticLoadBalancingV2Listener =============================

type ElasticLoadBalancingV2Listener struct {
	Description   aws.ElasticLoadBalancingV2ListenerDescription `json:"description"`
	Metadata      aws.Metadata                                  `json:"metadata"`
	ResourceJobID int                                           `json:"resource_job_id"`
	SourceJobID   int                                           `json:"source_job_id"`
	ResourceType  string                                        `json:"resource_type"`
	SourceType    string                                        `json:"source_type"`
	ID            string                                        `json:"id"`
	SourceID      string                                        `json:"source_id"`
}

type ElasticLoadBalancingV2ListenerHit struct {
	ID      string                         `json:"_id"`
	Score   float64                        `json:"_score"`
	Index   string                         `json:"_index"`
	Type    string                         `json:"_type"`
	Version int64                          `json:"_version,omitempty"`
	Source  ElasticLoadBalancingV2Listener `json:"_source"`
	Sort    []interface{}                  `json:"sort"`
}

type ElasticLoadBalancingV2ListenerHits struct {
	Total SearchTotal                         `json:"total"`
	Hits  []ElasticLoadBalancingV2ListenerHit `json:"hits"`
}

type ElasticLoadBalancingV2ListenerSearchResponse struct {
	PitID string                             `json:"pit_id"`
	Hits  ElasticLoadBalancingV2ListenerHits `json:"hits"`
}

type ElasticLoadBalancingV2ListenerPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewElasticLoadBalancingV2ListenerPaginator(filters []BoolFilter, limit *int64) (ElasticLoadBalancingV2ListenerPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_elasticloadbalancingv2_listener", filters, limit)
	if err != nil {
		return ElasticLoadBalancingV2ListenerPaginator{}, err
	}

	p := ElasticLoadBalancingV2ListenerPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ElasticLoadBalancingV2ListenerPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ElasticLoadBalancingV2ListenerPaginator) NextPage(ctx context.Context) ([]ElasticLoadBalancingV2Listener, error) {
	var response ElasticLoadBalancingV2ListenerSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ElasticLoadBalancingV2Listener
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listElasticLoadBalancingV2ListenerFilters = map[string]string{}

func ListElasticLoadBalancingV2Listener(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListElasticLoadBalancingV2Listener")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewElasticLoadBalancingV2ListenerPaginator(buildFilter(d.KeyColumnQuals, listElasticLoadBalancingV2ListenerFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getElasticLoadBalancingV2ListenerFilters = map[string]string{
	"arn": "description.Listener.ListenerArn",
}

func GetElasticLoadBalancingV2Listener(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetElasticLoadBalancingV2Listener")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewElasticLoadBalancingV2ListenerPaginator(buildFilter(d.KeyColumnQuals, getElasticLoadBalancingV2ListenerFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ElasticLoadBalancingV2Listener =============================

// ==========================  START: FSXFileSystem =============================

type FSXFileSystem struct {
	Description   aws.FSXFileSystemDescription `json:"description"`
	Metadata      aws.Metadata                 `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	SourceID      string                       `json:"source_id"`
}

type FSXFileSystemHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  FSXFileSystem `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type FSXFileSystemHits struct {
	Total SearchTotal        `json:"total"`
	Hits  []FSXFileSystemHit `json:"hits"`
}

type FSXFileSystemSearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  FSXFileSystemHits `json:"hits"`
}

type FSXFileSystemPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewFSXFileSystemPaginator(filters []BoolFilter, limit *int64) (FSXFileSystemPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_fsx_filesystem", filters, limit)
	if err != nil {
		return FSXFileSystemPaginator{}, err
	}

	p := FSXFileSystemPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p FSXFileSystemPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p FSXFileSystemPaginator) NextPage(ctx context.Context) ([]FSXFileSystem, error) {
	var response FSXFileSystemSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []FSXFileSystem
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listFSXFileSystemFilters = map[string]string{}

func ListFSXFileSystem(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListFSXFileSystem")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewFSXFileSystemPaginator(buildFilter(d.KeyColumnQuals, listFSXFileSystemFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getFSXFileSystemFilters = map[string]string{
	"file_system_id": "description.FileSystem.FileSystemId",
}

func GetFSXFileSystem(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetFSXFileSystem")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewFSXFileSystemPaginator(buildFilter(d.KeyColumnQuals, getFSXFileSystemFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: FSXFileSystem =============================

// ==========================  START: ApplicationAutoScalingTarget =============================

type ApplicationAutoScalingTarget struct {
	Description   aws.ApplicationAutoScalingTargetDescription `json:"description"`
	Metadata      aws.Metadata                                `json:"metadata"`
	ResourceJobID int                                         `json:"resource_job_id"`
	SourceJobID   int                                         `json:"source_job_id"`
	ResourceType  string                                      `json:"resource_type"`
	SourceType    string                                      `json:"source_type"`
	ID            string                                      `json:"id"`
	SourceID      string                                      `json:"source_id"`
}

type ApplicationAutoScalingTargetHit struct {
	ID      string                       `json:"_id"`
	Score   float64                      `json:"_score"`
	Index   string                       `json:"_index"`
	Type    string                       `json:"_type"`
	Version int64                        `json:"_version,omitempty"`
	Source  ApplicationAutoScalingTarget `json:"_source"`
	Sort    []interface{}                `json:"sort"`
}

type ApplicationAutoScalingTargetHits struct {
	Total SearchTotal                       `json:"total"`
	Hits  []ApplicationAutoScalingTargetHit `json:"hits"`
}

type ApplicationAutoScalingTargetSearchResponse struct {
	PitID string                           `json:"pit_id"`
	Hits  ApplicationAutoScalingTargetHits `json:"hits"`
}

type ApplicationAutoScalingTargetPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewApplicationAutoScalingTargetPaginator(filters []BoolFilter, limit *int64) (ApplicationAutoScalingTargetPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_applicationautoscaling_target", filters, limit)
	if err != nil {
		return ApplicationAutoScalingTargetPaginator{}, err
	}

	p := ApplicationAutoScalingTargetPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ApplicationAutoScalingTargetPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ApplicationAutoScalingTargetPaginator) NextPage(ctx context.Context) ([]ApplicationAutoScalingTarget, error) {
	var response ApplicationAutoScalingTargetSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ApplicationAutoScalingTarget
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listApplicationAutoScalingTargetFilters = map[string]string{
	"resource_id":        "description.ScalableTarget.ResourceId",
	"scalable_dimension": "description.ScalableTarget.ScalableDimension",
	"service_namespace":  "description.ScalableTarget.ServiceNamespace",
}

func ListApplicationAutoScalingTarget(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListApplicationAutoScalingTarget")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewApplicationAutoScalingTargetPaginator(buildFilter(d.KeyColumnQuals, listApplicationAutoScalingTargetFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getApplicationAutoScalingTargetFilters = map[string]string{
	"resource_id":       "description.ScalableTarget.ResourceId",
	"service_namespace": "description.ScalableTarget.ServiceNamespace",
}

func GetApplicationAutoScalingTarget(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetApplicationAutoScalingTarget")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewApplicationAutoScalingTargetPaginator(buildFilter(d.KeyColumnQuals, getApplicationAutoScalingTargetFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ApplicationAutoScalingTarget =============================

// ==========================  START: AutoScalingGroup =============================

type AutoScalingGroup struct {
	Description   aws.AutoScalingGroupDescription `json:"description"`
	Metadata      aws.Metadata                    `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	SourceID      string                          `json:"source_id"`
}

type AutoScalingGroupHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  AutoScalingGroup `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type AutoScalingGroupHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []AutoScalingGroupHit `json:"hits"`
}

type AutoScalingGroupSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  AutoScalingGroupHits `json:"hits"`
}

type AutoScalingGroupPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewAutoScalingGroupPaginator(filters []BoolFilter, limit *int64) (AutoScalingGroupPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_autoscaling_autoscalinggroup", filters, limit)
	if err != nil {
		return AutoScalingGroupPaginator{}, err
	}

	p := AutoScalingGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AutoScalingGroupPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p AutoScalingGroupPaginator) NextPage(ctx context.Context) ([]AutoScalingGroup, error) {
	var response AutoScalingGroupSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AutoScalingGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listAutoScalingGroupFilters = map[string]string{}

func ListAutoScalingGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAutoScalingGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewAutoScalingGroupPaginator(buildFilter(d.KeyColumnQuals, listAutoScalingGroupFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAutoScalingGroupFilters = map[string]string{
	"name": "description.AutoScalingGroup.AutoScalingGroupName",
}

func GetAutoScalingGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAutoScalingGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewAutoScalingGroupPaginator(buildFilter(d.KeyColumnQuals, getAutoScalingGroupFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AutoScalingGroup =============================

// ==========================  START: AutoScalingLaunchConfiguration =============================

type AutoScalingLaunchConfiguration struct {
	Description   aws.AutoScalingLaunchConfigurationDescription `json:"description"`
	Metadata      aws.Metadata                                  `json:"metadata"`
	ResourceJobID int                                           `json:"resource_job_id"`
	SourceJobID   int                                           `json:"source_job_id"`
	ResourceType  string                                        `json:"resource_type"`
	SourceType    string                                        `json:"source_type"`
	ID            string                                        `json:"id"`
	SourceID      string                                        `json:"source_id"`
}

type AutoScalingLaunchConfigurationHit struct {
	ID      string                         `json:"_id"`
	Score   float64                        `json:"_score"`
	Index   string                         `json:"_index"`
	Type    string                         `json:"_type"`
	Version int64                          `json:"_version,omitempty"`
	Source  AutoScalingLaunchConfiguration `json:"_source"`
	Sort    []interface{}                  `json:"sort"`
}

type AutoScalingLaunchConfigurationHits struct {
	Total SearchTotal                         `json:"total"`
	Hits  []AutoScalingLaunchConfigurationHit `json:"hits"`
}

type AutoScalingLaunchConfigurationSearchResponse struct {
	PitID string                             `json:"pit_id"`
	Hits  AutoScalingLaunchConfigurationHits `json:"hits"`
}

type AutoScalingLaunchConfigurationPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewAutoScalingLaunchConfigurationPaginator(filters []BoolFilter, limit *int64) (AutoScalingLaunchConfigurationPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_autoscaling_launchconfiguration", filters, limit)
	if err != nil {
		return AutoScalingLaunchConfigurationPaginator{}, err
	}

	p := AutoScalingLaunchConfigurationPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AutoScalingLaunchConfigurationPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p AutoScalingLaunchConfigurationPaginator) NextPage(ctx context.Context) ([]AutoScalingLaunchConfiguration, error) {
	var response AutoScalingLaunchConfigurationSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AutoScalingLaunchConfiguration
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listAutoScalingLaunchConfigurationFilters = map[string]string{}

func ListAutoScalingLaunchConfiguration(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAutoScalingLaunchConfiguration")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewAutoScalingLaunchConfigurationPaginator(buildFilter(d.KeyColumnQuals, listAutoScalingLaunchConfigurationFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAutoScalingLaunchConfigurationFilters = map[string]string{
	"name": "description.LaunchConfiguration.LaunchConfigurationName",
}

func GetAutoScalingLaunchConfiguration(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAutoScalingLaunchConfiguration")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewAutoScalingLaunchConfigurationPaginator(buildFilter(d.KeyColumnQuals, getAutoScalingLaunchConfigurationFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AutoScalingLaunchConfiguration =============================

// ==========================  START: CertificateManagerCertificate =============================

type CertificateManagerCertificate struct {
	Description   aws.CertificateManagerCertificateDescription `json:"description"`
	Metadata      aws.Metadata                                 `json:"metadata"`
	ResourceJobID int                                          `json:"resource_job_id"`
	SourceJobID   int                                          `json:"source_job_id"`
	ResourceType  string                                       `json:"resource_type"`
	SourceType    string                                       `json:"source_type"`
	ID            string                                       `json:"id"`
	SourceID      string                                       `json:"source_id"`
}

type CertificateManagerCertificateHit struct {
	ID      string                        `json:"_id"`
	Score   float64                       `json:"_score"`
	Index   string                        `json:"_index"`
	Type    string                        `json:"_type"`
	Version int64                         `json:"_version,omitempty"`
	Source  CertificateManagerCertificate `json:"_source"`
	Sort    []interface{}                 `json:"sort"`
}

type CertificateManagerCertificateHits struct {
	Total SearchTotal                        `json:"total"`
	Hits  []CertificateManagerCertificateHit `json:"hits"`
}

type CertificateManagerCertificateSearchResponse struct {
	PitID string                            `json:"pit_id"`
	Hits  CertificateManagerCertificateHits `json:"hits"`
}

type CertificateManagerCertificatePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCertificateManagerCertificatePaginator(filters []BoolFilter, limit *int64) (CertificateManagerCertificatePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_certificatemanager_certificate", filters, limit)
	if err != nil {
		return CertificateManagerCertificatePaginator{}, err
	}

	p := CertificateManagerCertificatePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CertificateManagerCertificatePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CertificateManagerCertificatePaginator) NextPage(ctx context.Context) ([]CertificateManagerCertificate, error) {
	var response CertificateManagerCertificateSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CertificateManagerCertificate
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCertificateManagerCertificateFilters = map[string]string{
	"status": "description.Certificate.Status",
}

func ListCertificateManagerCertificate(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCertificateManagerCertificate")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCertificateManagerCertificatePaginator(buildFilter(d.KeyColumnQuals, listCertificateManagerCertificateFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCertificateManagerCertificateFilters = map[string]string{
	"certificate_arn": "description.Certificate.CertificateArn",
}

func GetCertificateManagerCertificate(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCertificateManagerCertificate")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCertificateManagerCertificatePaginator(buildFilter(d.KeyColumnQuals, getCertificateManagerCertificateFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CertificateManagerCertificate =============================

// ==========================  START: CloudTrailTrail =============================

type CloudTrailTrail struct {
	Description   aws.CloudTrailTrailDescription `json:"description"`
	Metadata      aws.Metadata                   `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	SourceID      string                         `json:"source_id"`
}

type CloudTrailTrailHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  CloudTrailTrail `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type CloudTrailTrailHits struct {
	Total SearchTotal          `json:"total"`
	Hits  []CloudTrailTrailHit `json:"hits"`
}

type CloudTrailTrailSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  CloudTrailTrailHits `json:"hits"`
}

type CloudTrailTrailPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCloudTrailTrailPaginator(filters []BoolFilter, limit *int64) (CloudTrailTrailPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_cloudtrail_trail", filters, limit)
	if err != nil {
		return CloudTrailTrailPaginator{}, err
	}

	p := CloudTrailTrailPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CloudTrailTrailPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CloudTrailTrailPaginator) NextPage(ctx context.Context) ([]CloudTrailTrail, error) {
	var response CloudTrailTrailSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CloudTrailTrail
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCloudTrailTrailFilters = map[string]string{}

func ListCloudTrailTrail(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCloudTrailTrail")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCloudTrailTrailPaginator(buildFilter(d.KeyColumnQuals, listCloudTrailTrailFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCloudTrailTrailFilters = map[string]string{
	"arn":  "description.Trail.TrailARN",
	"name": "description.Trail.Name",
}

func GetCloudTrailTrail(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCloudTrailTrail")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCloudTrailTrailPaginator(buildFilter(d.KeyColumnQuals, getCloudTrailTrailFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CloudTrailTrail =============================

// ==========================  START: IAMAccount =============================

type IAMAccount struct {
	Description   aws.IAMAccountDescription `json:"description"`
	Metadata      aws.Metadata              `json:"metadata"`
	ResourceJobID int                       `json:"resource_job_id"`
	SourceJobID   int                       `json:"source_job_id"`
	ResourceType  string                    `json:"resource_type"`
	SourceType    string                    `json:"source_type"`
	ID            string                    `json:"id"`
	SourceID      string                    `json:"source_id"`
}

type IAMAccountHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  IAMAccount    `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type IAMAccountHits struct {
	Total SearchTotal     `json:"total"`
	Hits  []IAMAccountHit `json:"hits"`
}

type IAMAccountSearchResponse struct {
	PitID string         `json:"pit_id"`
	Hits  IAMAccountHits `json:"hits"`
}

type IAMAccountPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewIAMAccountPaginator(filters []BoolFilter, limit *int64) (IAMAccountPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_iam_account", filters, limit)
	if err != nil {
		return IAMAccountPaginator{}, err
	}

	p := IAMAccountPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p IAMAccountPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p IAMAccountPaginator) NextPage(ctx context.Context) ([]IAMAccount, error) {
	var response IAMAccountSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []IAMAccount
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listIAMAccountFilters = map[string]string{}

func ListIAMAccount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListIAMAccount")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewIAMAccountPaginator(buildFilter(d.KeyColumnQuals, listIAMAccountFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getIAMAccountFilters = map[string]string{}

func GetIAMAccount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetIAMAccount")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewIAMAccountPaginator(buildFilter(d.KeyColumnQuals, getIAMAccountFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: IAMAccount =============================

// ==========================  START: IAMAccountSummary =============================

type IAMAccountSummary struct {
	Description   aws.IAMAccountSummaryDescription `json:"description"`
	Metadata      aws.Metadata                     `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	SourceID      string                           `json:"source_id"`
}

type IAMAccountSummaryHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  IAMAccountSummary `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type IAMAccountSummaryHits struct {
	Total SearchTotal            `json:"total"`
	Hits  []IAMAccountSummaryHit `json:"hits"`
}

type IAMAccountSummarySearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  IAMAccountSummaryHits `json:"hits"`
}

type IAMAccountSummaryPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewIAMAccountSummaryPaginator(filters []BoolFilter, limit *int64) (IAMAccountSummaryPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_iam_accountsummary", filters, limit)
	if err != nil {
		return IAMAccountSummaryPaginator{}, err
	}

	p := IAMAccountSummaryPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p IAMAccountSummaryPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p IAMAccountSummaryPaginator) NextPage(ctx context.Context) ([]IAMAccountSummary, error) {
	var response IAMAccountSummarySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []IAMAccountSummary
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listIAMAccountSummaryFilters = map[string]string{}

func ListIAMAccountSummary(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListIAMAccountSummary")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewIAMAccountSummaryPaginator(buildFilter(d.KeyColumnQuals, listIAMAccountSummaryFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getIAMAccountSummaryFilters = map[string]string{}

func GetIAMAccountSummary(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetIAMAccountSummary")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewIAMAccountSummaryPaginator(buildFilter(d.KeyColumnQuals, getIAMAccountSummaryFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: IAMAccountSummary =============================

// ==========================  START: IAMAccessKey =============================

type IAMAccessKey struct {
	Description   aws.IAMAccessKeyDescription `json:"description"`
	Metadata      aws.Metadata                `json:"metadata"`
	ResourceJobID int                         `json:"resource_job_id"`
	SourceJobID   int                         `json:"source_job_id"`
	ResourceType  string                      `json:"resource_type"`
	SourceType    string                      `json:"source_type"`
	ID            string                      `json:"id"`
	SourceID      string                      `json:"source_id"`
}

type IAMAccessKeyHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  IAMAccessKey  `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type IAMAccessKeyHits struct {
	Total SearchTotal       `json:"total"`
	Hits  []IAMAccessKeyHit `json:"hits"`
}

type IAMAccessKeySearchResponse struct {
	PitID string           `json:"pit_id"`
	Hits  IAMAccessKeyHits `json:"hits"`
}

type IAMAccessKeyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewIAMAccessKeyPaginator(filters []BoolFilter, limit *int64) (IAMAccessKeyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_iam_accesskey", filters, limit)
	if err != nil {
		return IAMAccessKeyPaginator{}, err
	}

	p := IAMAccessKeyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p IAMAccessKeyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p IAMAccessKeyPaginator) NextPage(ctx context.Context) ([]IAMAccessKey, error) {
	var response IAMAccessKeySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []IAMAccessKey
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listIAMAccessKeyFilters = map[string]string{}

func ListIAMAccessKey(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListIAMAccessKey")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewIAMAccessKeyPaginator(buildFilter(d.KeyColumnQuals, listIAMAccessKeyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getIAMAccessKeyFilters = map[string]string{}

func GetIAMAccessKey(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetIAMAccessKey")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewIAMAccessKeyPaginator(buildFilter(d.KeyColumnQuals, getIAMAccessKeyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: IAMAccessKey =============================

// ==========================  START: IAMAccountPasswordPolicy =============================

type IAMAccountPasswordPolicy struct {
	Description   aws.IAMAccountPasswordPolicyDescription `json:"description"`
	Metadata      aws.Metadata                            `json:"metadata"`
	ResourceJobID int                                     `json:"resource_job_id"`
	SourceJobID   int                                     `json:"source_job_id"`
	ResourceType  string                                  `json:"resource_type"`
	SourceType    string                                  `json:"source_type"`
	ID            string                                  `json:"id"`
	SourceID      string                                  `json:"source_id"`
}

type IAMAccountPasswordPolicyHit struct {
	ID      string                   `json:"_id"`
	Score   float64                  `json:"_score"`
	Index   string                   `json:"_index"`
	Type    string                   `json:"_type"`
	Version int64                    `json:"_version,omitempty"`
	Source  IAMAccountPasswordPolicy `json:"_source"`
	Sort    []interface{}            `json:"sort"`
}

type IAMAccountPasswordPolicyHits struct {
	Total SearchTotal                   `json:"total"`
	Hits  []IAMAccountPasswordPolicyHit `json:"hits"`
}

type IAMAccountPasswordPolicySearchResponse struct {
	PitID string                       `json:"pit_id"`
	Hits  IAMAccountPasswordPolicyHits `json:"hits"`
}

type IAMAccountPasswordPolicyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewIAMAccountPasswordPolicyPaginator(filters []BoolFilter, limit *int64) (IAMAccountPasswordPolicyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_iam_accountpasswordpolicy", filters, limit)
	if err != nil {
		return IAMAccountPasswordPolicyPaginator{}, err
	}

	p := IAMAccountPasswordPolicyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p IAMAccountPasswordPolicyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p IAMAccountPasswordPolicyPaginator) NextPage(ctx context.Context) ([]IAMAccountPasswordPolicy, error) {
	var response IAMAccountPasswordPolicySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []IAMAccountPasswordPolicy
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listIAMAccountPasswordPolicyFilters = map[string]string{}

func ListIAMAccountPasswordPolicy(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListIAMAccountPasswordPolicy")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewIAMAccountPasswordPolicyPaginator(buildFilter(d.KeyColumnQuals, listIAMAccountPasswordPolicyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getIAMAccountPasswordPolicyFilters = map[string]string{}

func GetIAMAccountPasswordPolicy(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetIAMAccountPasswordPolicy")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewIAMAccountPasswordPolicyPaginator(buildFilter(d.KeyColumnQuals, getIAMAccountPasswordPolicyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: IAMAccountPasswordPolicy =============================

// ==========================  START: IAMUser =============================

type IAMUser struct {
	Description   aws.IAMUserDescription `json:"description"`
	Metadata      aws.Metadata           `json:"metadata"`
	ResourceJobID int                    `json:"resource_job_id"`
	SourceJobID   int                    `json:"source_job_id"`
	ResourceType  string                 `json:"resource_type"`
	SourceType    string                 `json:"source_type"`
	ID            string                 `json:"id"`
	SourceID      string                 `json:"source_id"`
}

type IAMUserHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  IAMUser       `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type IAMUserHits struct {
	Total SearchTotal  `json:"total"`
	Hits  []IAMUserHit `json:"hits"`
}

type IAMUserSearchResponse struct {
	PitID string      `json:"pit_id"`
	Hits  IAMUserHits `json:"hits"`
}

type IAMUserPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewIAMUserPaginator(filters []BoolFilter, limit *int64) (IAMUserPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_iam_user", filters, limit)
	if err != nil {
		return IAMUserPaginator{}, err
	}

	p := IAMUserPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p IAMUserPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p IAMUserPaginator) NextPage(ctx context.Context) ([]IAMUser, error) {
	var response IAMUserSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []IAMUser
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listIAMUserFilters = map[string]string{}

func ListIAMUser(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListIAMUser")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewIAMUserPaginator(buildFilter(d.KeyColumnQuals, listIAMUserFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getIAMUserFilters = map[string]string{
	"arn":  "description.User.Arn",
	"name": "description.User.UserName",
}

func GetIAMUser(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetIAMUser")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewIAMUserPaginator(buildFilter(d.KeyColumnQuals, getIAMUserFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: IAMUser =============================

// ==========================  START: IAMGroup =============================

type IAMGroup struct {
	Description   aws.IAMGroupDescription `json:"description"`
	Metadata      aws.Metadata            `json:"metadata"`
	ResourceJobID int                     `json:"resource_job_id"`
	SourceJobID   int                     `json:"source_job_id"`
	ResourceType  string                  `json:"resource_type"`
	SourceType    string                  `json:"source_type"`
	ID            string                  `json:"id"`
	SourceID      string                  `json:"source_id"`
}

type IAMGroupHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  IAMGroup      `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type IAMGroupHits struct {
	Total SearchTotal   `json:"total"`
	Hits  []IAMGroupHit `json:"hits"`
}

type IAMGroupSearchResponse struct {
	PitID string       `json:"pit_id"`
	Hits  IAMGroupHits `json:"hits"`
}

type IAMGroupPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewIAMGroupPaginator(filters []BoolFilter, limit *int64) (IAMGroupPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_iam_group", filters, limit)
	if err != nil {
		return IAMGroupPaginator{}, err
	}

	p := IAMGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p IAMGroupPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p IAMGroupPaginator) NextPage(ctx context.Context) ([]IAMGroup, error) {
	var response IAMGroupSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []IAMGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listIAMGroupFilters = map[string]string{}

func ListIAMGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListIAMGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewIAMGroupPaginator(buildFilter(d.KeyColumnQuals, listIAMGroupFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getIAMGroupFilters = map[string]string{
	"arn":  "description.Group.Arn",
	"name": "description.Group.GroupName",
}

func GetIAMGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetIAMGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewIAMGroupPaginator(buildFilter(d.KeyColumnQuals, getIAMGroupFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: IAMGroup =============================

// ==========================  START: IAMRole =============================

type IAMRole struct {
	Description   aws.IAMRoleDescription `json:"description"`
	Metadata      aws.Metadata           `json:"metadata"`
	ResourceJobID int                    `json:"resource_job_id"`
	SourceJobID   int                    `json:"source_job_id"`
	ResourceType  string                 `json:"resource_type"`
	SourceType    string                 `json:"source_type"`
	ID            string                 `json:"id"`
	SourceID      string                 `json:"source_id"`
}

type IAMRoleHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  IAMRole       `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type IAMRoleHits struct {
	Total SearchTotal  `json:"total"`
	Hits  []IAMRoleHit `json:"hits"`
}

type IAMRoleSearchResponse struct {
	PitID string      `json:"pit_id"`
	Hits  IAMRoleHits `json:"hits"`
}

type IAMRolePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewIAMRolePaginator(filters []BoolFilter, limit *int64) (IAMRolePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_iam_role", filters, limit)
	if err != nil {
		return IAMRolePaginator{}, err
	}

	p := IAMRolePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p IAMRolePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p IAMRolePaginator) NextPage(ctx context.Context) ([]IAMRole, error) {
	var response IAMRoleSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []IAMRole
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listIAMRoleFilters = map[string]string{}

func ListIAMRole(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListIAMRole")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewIAMRolePaginator(buildFilter(d.KeyColumnQuals, listIAMRoleFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getIAMRoleFilters = map[string]string{
	"arn":  "description.Role.Arn",
	"name": "description.Role.RoleName",
}

func GetIAMRole(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetIAMRole")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewIAMRolePaginator(buildFilter(d.KeyColumnQuals, getIAMRoleFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: IAMRole =============================

// ==========================  START: IAMServerCertificate =============================

type IAMServerCertificate struct {
	Description   aws.IAMServerCertificateDescription `json:"description"`
	Metadata      aws.Metadata                        `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	SourceID      string                              `json:"source_id"`
}

type IAMServerCertificateHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  IAMServerCertificate `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type IAMServerCertificateHits struct {
	Total SearchTotal               `json:"total"`
	Hits  []IAMServerCertificateHit `json:"hits"`
}

type IAMServerCertificateSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  IAMServerCertificateHits `json:"hits"`
}

type IAMServerCertificatePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewIAMServerCertificatePaginator(filters []BoolFilter, limit *int64) (IAMServerCertificatePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_iam_servercertificate", filters, limit)
	if err != nil {
		return IAMServerCertificatePaginator{}, err
	}

	p := IAMServerCertificatePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p IAMServerCertificatePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p IAMServerCertificatePaginator) NextPage(ctx context.Context) ([]IAMServerCertificate, error) {
	var response IAMServerCertificateSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []IAMServerCertificate
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listIAMServerCertificateFilters = map[string]string{}

func ListIAMServerCertificate(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListIAMServerCertificate")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewIAMServerCertificatePaginator(buildFilter(d.KeyColumnQuals, listIAMServerCertificateFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getIAMServerCertificateFilters = map[string]string{
	"name": "description.ServerCertificate.ServerCertificateMetadata.ServerCertificateName",
}

func GetIAMServerCertificate(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetIAMServerCertificate")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewIAMServerCertificatePaginator(buildFilter(d.KeyColumnQuals, getIAMServerCertificateFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: IAMServerCertificate =============================

// ==========================  START: IAMPolicy =============================

type IAMPolicy struct {
	Description   aws.IAMPolicyDescription `json:"description"`
	Metadata      aws.Metadata             `json:"metadata"`
	ResourceJobID int                      `json:"resource_job_id"`
	SourceJobID   int                      `json:"source_job_id"`
	ResourceType  string                   `json:"resource_type"`
	SourceType    string                   `json:"source_type"`
	ID            string                   `json:"id"`
	SourceID      string                   `json:"source_id"`
}

type IAMPolicyHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  IAMPolicy     `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type IAMPolicyHits struct {
	Total SearchTotal    `json:"total"`
	Hits  []IAMPolicyHit `json:"hits"`
}

type IAMPolicySearchResponse struct {
	PitID string        `json:"pit_id"`
	Hits  IAMPolicyHits `json:"hits"`
}

type IAMPolicyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewIAMPolicyPaginator(filters []BoolFilter, limit *int64) (IAMPolicyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_iam_policy", filters, limit)
	if err != nil {
		return IAMPolicyPaginator{}, err
	}

	p := IAMPolicyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p IAMPolicyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p IAMPolicyPaginator) NextPage(ctx context.Context) ([]IAMPolicy, error) {
	var response IAMPolicySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []IAMPolicy
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listIAMPolicyFilters = map[string]string{}

func ListIAMPolicy(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListIAMPolicy")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewIAMPolicyPaginator(buildFilter(d.KeyColumnQuals, listIAMPolicyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getIAMPolicyFilters = map[string]string{
	"arn": "description.Policy.Arn",
}

func GetIAMPolicy(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetIAMPolicy")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewIAMPolicyPaginator(buildFilter(d.KeyColumnQuals, getIAMPolicyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: IAMPolicy =============================

// ==========================  START: IAMCredentialReport =============================

type IAMCredentialReport struct {
	Description   aws.IAMCredentialReportDescription `json:"description"`
	Metadata      aws.Metadata                       `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	SourceID      string                             `json:"source_id"`
}

type IAMCredentialReportHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  IAMCredentialReport `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type IAMCredentialReportHits struct {
	Total SearchTotal              `json:"total"`
	Hits  []IAMCredentialReportHit `json:"hits"`
}

type IAMCredentialReportSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  IAMCredentialReportHits `json:"hits"`
}

type IAMCredentialReportPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewIAMCredentialReportPaginator(filters []BoolFilter, limit *int64) (IAMCredentialReportPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_iam_credentialreport", filters, limit)
	if err != nil {
		return IAMCredentialReportPaginator{}, err
	}

	p := IAMCredentialReportPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p IAMCredentialReportPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p IAMCredentialReportPaginator) NextPage(ctx context.Context) ([]IAMCredentialReport, error) {
	var response IAMCredentialReportSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []IAMCredentialReport
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listIAMCredentialReportFilters = map[string]string{}

func ListIAMCredentialReport(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListIAMCredentialReport")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewIAMCredentialReportPaginator(buildFilter(d.KeyColumnQuals, listIAMCredentialReportFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getIAMCredentialReportFilters = map[string]string{}

func GetIAMCredentialReport(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetIAMCredentialReport")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewIAMCredentialReportPaginator(buildFilter(d.KeyColumnQuals, getIAMCredentialReportFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: IAMCredentialReport =============================

// ==========================  START: IAMVirtualMFADevice =============================

type IAMVirtualMFADevice struct {
	Description   aws.IAMVirtualMFADeviceDescription `json:"description"`
	Metadata      aws.Metadata                       `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	SourceID      string                             `json:"source_id"`
}

type IAMVirtualMFADeviceHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  IAMVirtualMFADevice `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type IAMVirtualMFADeviceHits struct {
	Total SearchTotal              `json:"total"`
	Hits  []IAMVirtualMFADeviceHit `json:"hits"`
}

type IAMVirtualMFADeviceSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  IAMVirtualMFADeviceHits `json:"hits"`
}

type IAMVirtualMFADevicePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewIAMVirtualMFADevicePaginator(filters []BoolFilter, limit *int64) (IAMVirtualMFADevicePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_iam_virtualmfadevices", filters, limit)
	if err != nil {
		return IAMVirtualMFADevicePaginator{}, err
	}

	p := IAMVirtualMFADevicePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p IAMVirtualMFADevicePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p IAMVirtualMFADevicePaginator) NextPage(ctx context.Context) ([]IAMVirtualMFADevice, error) {
	var response IAMVirtualMFADeviceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []IAMVirtualMFADevice
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listIAMVirtualMFADeviceFilters = map[string]string{}

func ListIAMVirtualMFADevice(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListIAMVirtualMFADevice")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewIAMVirtualMFADevicePaginator(buildFilter(d.KeyColumnQuals, listIAMVirtualMFADeviceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getIAMVirtualMFADeviceFilters = map[string]string{}

func GetIAMVirtualMFADevice(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetIAMVirtualMFADevice")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewIAMVirtualMFADevicePaginator(buildFilter(d.KeyColumnQuals, getIAMVirtualMFADeviceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: IAMVirtualMFADevice =============================

// ==========================  START: RDSDBCluster =============================

type RDSDBCluster struct {
	Description   aws.RDSDBClusterDescription `json:"description"`
	Metadata      aws.Metadata                `json:"metadata"`
	ResourceJobID int                         `json:"resource_job_id"`
	SourceJobID   int                         `json:"source_job_id"`
	ResourceType  string                      `json:"resource_type"`
	SourceType    string                      `json:"source_type"`
	ID            string                      `json:"id"`
	SourceID      string                      `json:"source_id"`
}

type RDSDBClusterHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  RDSDBCluster  `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type RDSDBClusterHits struct {
	Total SearchTotal       `json:"total"`
	Hits  []RDSDBClusterHit `json:"hits"`
}

type RDSDBClusterSearchResponse struct {
	PitID string           `json:"pit_id"`
	Hits  RDSDBClusterHits `json:"hits"`
}

type RDSDBClusterPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewRDSDBClusterPaginator(filters []BoolFilter, limit *int64) (RDSDBClusterPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_rds_dbcluster", filters, limit)
	if err != nil {
		return RDSDBClusterPaginator{}, err
	}

	p := RDSDBClusterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p RDSDBClusterPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p RDSDBClusterPaginator) NextPage(ctx context.Context) ([]RDSDBCluster, error) {
	var response RDSDBClusterSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []RDSDBCluster
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listRDSDBClusterFilters = map[string]string{}

func ListRDSDBCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListRDSDBCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewRDSDBClusterPaginator(buildFilter(d.KeyColumnQuals, listRDSDBClusterFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getRDSDBClusterFilters = map[string]string{
	"db_cluster_identifier": "description.DBCluster.DBClusterIdentifier",
}

func GetRDSDBCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetRDSDBCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewRDSDBClusterPaginator(buildFilter(d.KeyColumnQuals, getRDSDBClusterFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: RDSDBCluster =============================

// ==========================  START: RDSDBClusterSnapshot =============================

type RDSDBClusterSnapshot struct {
	Description   aws.RDSDBClusterSnapshotDescription `json:"description"`
	Metadata      aws.Metadata                        `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	SourceID      string                              `json:"source_id"`
}

type RDSDBClusterSnapshotHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  RDSDBClusterSnapshot `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type RDSDBClusterSnapshotHits struct {
	Total SearchTotal               `json:"total"`
	Hits  []RDSDBClusterSnapshotHit `json:"hits"`
}

type RDSDBClusterSnapshotSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  RDSDBClusterSnapshotHits `json:"hits"`
}

type RDSDBClusterSnapshotPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewRDSDBClusterSnapshotPaginator(filters []BoolFilter, limit *int64) (RDSDBClusterSnapshotPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_rds_dbclustersnapshot", filters, limit)
	if err != nil {
		return RDSDBClusterSnapshotPaginator{}, err
	}

	p := RDSDBClusterSnapshotPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p RDSDBClusterSnapshotPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p RDSDBClusterSnapshotPaginator) NextPage(ctx context.Context) ([]RDSDBClusterSnapshot, error) {
	var response RDSDBClusterSnapshotSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []RDSDBClusterSnapshot
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listRDSDBClusterSnapshotFilters = map[string]string{
	"db_cluster_identifier":          "description.DBClusterSnapshot.DBClusterIdentifier",
	"db_cluster_snapshot_identifier": "description.DBClusterSnapshot.DBClusterSnapshotIdentifier",
	"engine":                         "description.DBClusterSnapshot.Engine",
	"type":                           "description.DBClusterSnapshot.SnapshotType",
}

func ListRDSDBClusterSnapshot(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListRDSDBClusterSnapshot")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewRDSDBClusterSnapshotPaginator(buildFilter(d.KeyColumnQuals, listRDSDBClusterSnapshotFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getRDSDBClusterSnapshotFilters = map[string]string{
	"db_cluster_snapshot_identifier": "description.DBClusterSnapshot.DBClusterIdentifier",
}

func GetRDSDBClusterSnapshot(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetRDSDBClusterSnapshot")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewRDSDBClusterSnapshotPaginator(buildFilter(d.KeyColumnQuals, getRDSDBClusterSnapshotFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: RDSDBClusterSnapshot =============================

// ==========================  START: RDSDBEventSubscription =============================

type RDSDBEventSubscription struct {
	Description   aws.RDSDBEventSubscriptionDescription `json:"description"`
	Metadata      aws.Metadata                          `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	SourceID      string                                `json:"source_id"`
}

type RDSDBEventSubscriptionHit struct {
	ID      string                 `json:"_id"`
	Score   float64                `json:"_score"`
	Index   string                 `json:"_index"`
	Type    string                 `json:"_type"`
	Version int64                  `json:"_version,omitempty"`
	Source  RDSDBEventSubscription `json:"_source"`
	Sort    []interface{}          `json:"sort"`
}

type RDSDBEventSubscriptionHits struct {
	Total SearchTotal                 `json:"total"`
	Hits  []RDSDBEventSubscriptionHit `json:"hits"`
}

type RDSDBEventSubscriptionSearchResponse struct {
	PitID string                     `json:"pit_id"`
	Hits  RDSDBEventSubscriptionHits `json:"hits"`
}

type RDSDBEventSubscriptionPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewRDSDBEventSubscriptionPaginator(filters []BoolFilter, limit *int64) (RDSDBEventSubscriptionPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_rds_eventsubscription", filters, limit)
	if err != nil {
		return RDSDBEventSubscriptionPaginator{}, err
	}

	p := RDSDBEventSubscriptionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p RDSDBEventSubscriptionPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p RDSDBEventSubscriptionPaginator) NextPage(ctx context.Context) ([]RDSDBEventSubscription, error) {
	var response RDSDBEventSubscriptionSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []RDSDBEventSubscription
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listRDSDBEventSubscriptionFilters = map[string]string{}

func ListRDSDBEventSubscription(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListRDSDBEventSubscription")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewRDSDBEventSubscriptionPaginator(buildFilter(d.KeyColumnQuals, listRDSDBEventSubscriptionFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getRDSDBEventSubscriptionFilters = map[string]string{
	"cust_subscription_id": "description.EventSubscription.CustSubscriptionId",
}

func GetRDSDBEventSubscription(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetRDSDBEventSubscription")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewRDSDBEventSubscriptionPaginator(buildFilter(d.KeyColumnQuals, getRDSDBEventSubscriptionFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: RDSDBEventSubscription =============================

// ==========================  START: RDSDBInstance =============================

type RDSDBInstance struct {
	Description   aws.RDSDBInstanceDescription `json:"description"`
	Metadata      aws.Metadata                 `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	SourceID      string                       `json:"source_id"`
}

type RDSDBInstanceHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  RDSDBInstance `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type RDSDBInstanceHits struct {
	Total SearchTotal        `json:"total"`
	Hits  []RDSDBInstanceHit `json:"hits"`
}

type RDSDBInstanceSearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  RDSDBInstanceHits `json:"hits"`
}

type RDSDBInstancePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewRDSDBInstancePaginator(filters []BoolFilter, limit *int64) (RDSDBInstancePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_rds_dbinstance", filters, limit)
	if err != nil {
		return RDSDBInstancePaginator{}, err
	}

	p := RDSDBInstancePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p RDSDBInstancePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p RDSDBInstancePaginator) NextPage(ctx context.Context) ([]RDSDBInstance, error) {
	var response RDSDBInstanceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []RDSDBInstance
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listRDSDBInstanceFilters = map[string]string{}

func ListRDSDBInstance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListRDSDBInstance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewRDSDBInstancePaginator(buildFilter(d.KeyColumnQuals, listRDSDBInstanceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getRDSDBInstanceFilters = map[string]string{
	"db_instance_identifier": "description.DBInstance.DBInstanceIdentifier",
}

func GetRDSDBInstance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetRDSDBInstance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewRDSDBInstancePaginator(buildFilter(d.KeyColumnQuals, getRDSDBInstanceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: RDSDBInstance =============================

// ==========================  START: RDSDBSnapshot =============================

type RDSDBSnapshot struct {
	Description   aws.RDSDBSnapshotDescription `json:"description"`
	Metadata      aws.Metadata                 `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	SourceID      string                       `json:"source_id"`
}

type RDSDBSnapshotHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  RDSDBSnapshot `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type RDSDBSnapshotHits struct {
	Total SearchTotal        `json:"total"`
	Hits  []RDSDBSnapshotHit `json:"hits"`
}

type RDSDBSnapshotSearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  RDSDBSnapshotHits `json:"hits"`
}

type RDSDBSnapshotPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewRDSDBSnapshotPaginator(filters []BoolFilter, limit *int64) (RDSDBSnapshotPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_rds_dbsnapshot", filters, limit)
	if err != nil {
		return RDSDBSnapshotPaginator{}, err
	}

	p := RDSDBSnapshotPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p RDSDBSnapshotPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p RDSDBSnapshotPaginator) NextPage(ctx context.Context) ([]RDSDBSnapshot, error) {
	var response RDSDBSnapshotSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []RDSDBSnapshot
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listRDSDBSnapshotFilters = map[string]string{}

func ListRDSDBSnapshot(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListRDSDBSnapshot")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewRDSDBSnapshotPaginator(buildFilter(d.KeyColumnQuals, listRDSDBSnapshotFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getRDSDBSnapshotFilters = map[string]string{
	"db_snapshot_identifier": "description.DBSnapshot.DBInstanceIdentifier",
}

func GetRDSDBSnapshot(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetRDSDBSnapshot")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewRDSDBSnapshotPaginator(buildFilter(d.KeyColumnQuals, getRDSDBSnapshotFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: RDSDBSnapshot =============================

// ==========================  START: RedshiftCluster =============================

type RedshiftCluster struct {
	Description   aws.RedshiftClusterDescription `json:"description"`
	Metadata      aws.Metadata                   `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	SourceID      string                         `json:"source_id"`
}

type RedshiftClusterHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  RedshiftCluster `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type RedshiftClusterHits struct {
	Total SearchTotal          `json:"total"`
	Hits  []RedshiftClusterHit `json:"hits"`
}

type RedshiftClusterSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  RedshiftClusterHits `json:"hits"`
}

type RedshiftClusterPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewRedshiftClusterPaginator(filters []BoolFilter, limit *int64) (RedshiftClusterPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_redshift_cluster", filters, limit)
	if err != nil {
		return RedshiftClusterPaginator{}, err
	}

	p := RedshiftClusterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p RedshiftClusterPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p RedshiftClusterPaginator) NextPage(ctx context.Context) ([]RedshiftCluster, error) {
	var response RedshiftClusterSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []RedshiftCluster
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listRedshiftClusterFilters = map[string]string{}

func ListRedshiftCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListRedshiftCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewRedshiftClusterPaginator(buildFilter(d.KeyColumnQuals, listRedshiftClusterFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getRedshiftClusterFilters = map[string]string{
	"cluster_identifier": "description.Cluster",
}

func GetRedshiftCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetRedshiftCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewRedshiftClusterPaginator(buildFilter(d.KeyColumnQuals, getRedshiftClusterFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: RedshiftCluster =============================

// ==========================  START: RedshiftClusterParameterGroup =============================

type RedshiftClusterParameterGroup struct {
	Description   aws.RedshiftClusterParameterGroupDescription `json:"description"`
	Metadata      aws.Metadata                                 `json:"metadata"`
	ResourceJobID int                                          `json:"resource_job_id"`
	SourceJobID   int                                          `json:"source_job_id"`
	ResourceType  string                                       `json:"resource_type"`
	SourceType    string                                       `json:"source_type"`
	ID            string                                       `json:"id"`
	SourceID      string                                       `json:"source_id"`
}

type RedshiftClusterParameterGroupHit struct {
	ID      string                        `json:"_id"`
	Score   float64                       `json:"_score"`
	Index   string                        `json:"_index"`
	Type    string                        `json:"_type"`
	Version int64                         `json:"_version,omitempty"`
	Source  RedshiftClusterParameterGroup `json:"_source"`
	Sort    []interface{}                 `json:"sort"`
}

type RedshiftClusterParameterGroupHits struct {
	Total SearchTotal                        `json:"total"`
	Hits  []RedshiftClusterParameterGroupHit `json:"hits"`
}

type RedshiftClusterParameterGroupSearchResponse struct {
	PitID string                            `json:"pit_id"`
	Hits  RedshiftClusterParameterGroupHits `json:"hits"`
}

type RedshiftClusterParameterGroupPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewRedshiftClusterParameterGroupPaginator(filters []BoolFilter, limit *int64) (RedshiftClusterParameterGroupPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_redshift_clusterparametergroup", filters, limit)
	if err != nil {
		return RedshiftClusterParameterGroupPaginator{}, err
	}

	p := RedshiftClusterParameterGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p RedshiftClusterParameterGroupPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p RedshiftClusterParameterGroupPaginator) NextPage(ctx context.Context) ([]RedshiftClusterParameterGroup, error) {
	var response RedshiftClusterParameterGroupSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []RedshiftClusterParameterGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listRedshiftClusterParameterGroupFilters = map[string]string{}

func ListRedshiftClusterParameterGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListRedshiftClusterParameterGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewRedshiftClusterParameterGroupPaginator(buildFilter(d.KeyColumnQuals, listRedshiftClusterParameterGroupFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getRedshiftClusterParameterGroupFilters = map[string]string{
	"name": "description.ClusterParameterGroup.ParameterGroupName",
}

func GetRedshiftClusterParameterGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetRedshiftClusterParameterGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewRedshiftClusterParameterGroupPaginator(buildFilter(d.KeyColumnQuals, getRedshiftClusterParameterGroupFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: RedshiftClusterParameterGroup =============================

// ==========================  START: SNSTopic =============================

type SNSTopic struct {
	Description   aws.SNSTopicDescription `json:"description"`
	Metadata      aws.Metadata            `json:"metadata"`
	ResourceJobID int                     `json:"resource_job_id"`
	SourceJobID   int                     `json:"source_job_id"`
	ResourceType  string                  `json:"resource_type"`
	SourceType    string                  `json:"source_type"`
	ID            string                  `json:"id"`
	SourceID      string                  `json:"source_id"`
}

type SNSTopicHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  SNSTopic      `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type SNSTopicHits struct {
	Total SearchTotal   `json:"total"`
	Hits  []SNSTopicHit `json:"hits"`
}

type SNSTopicSearchResponse struct {
	PitID string       `json:"pit_id"`
	Hits  SNSTopicHits `json:"hits"`
}

type SNSTopicPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSNSTopicPaginator(filters []BoolFilter, limit *int64) (SNSTopicPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_sns_topic", filters, limit)
	if err != nil {
		return SNSTopicPaginator{}, err
	}

	p := SNSTopicPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SNSTopicPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SNSTopicPaginator) NextPage(ctx context.Context) ([]SNSTopic, error) {
	var response SNSTopicSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SNSTopic
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSNSTopicFilters = map[string]string{}

func ListSNSTopic(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSNSTopic")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSNSTopicPaginator(buildFilter(d.KeyColumnQuals, listSNSTopicFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSNSTopicFilters = map[string]string{
	"topic_arn": "description.Attributes.TopicArn",
}

func GetSNSTopic(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSNSTopic")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSNSTopicPaginator(buildFilter(d.KeyColumnQuals, getSNSTopicFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SNSTopic =============================

// ==========================  START: SNSSubscription =============================

type SNSSubscription struct {
	Description   aws.SNSSubscriptionDescription `json:"description"`
	Metadata      aws.Metadata                   `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	SourceID      string                         `json:"source_id"`
}

type SNSSubscriptionHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  SNSSubscription `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type SNSSubscriptionHits struct {
	Total SearchTotal          `json:"total"`
	Hits  []SNSSubscriptionHit `json:"hits"`
}

type SNSSubscriptionSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  SNSSubscriptionHits `json:"hits"`
}

type SNSSubscriptionPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSNSSubscriptionPaginator(filters []BoolFilter, limit *int64) (SNSSubscriptionPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_sns_subscription", filters, limit)
	if err != nil {
		return SNSSubscriptionPaginator{}, err
	}

	p := SNSSubscriptionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SNSSubscriptionPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SNSSubscriptionPaginator) NextPage(ctx context.Context) ([]SNSSubscription, error) {
	var response SNSSubscriptionSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SNSSubscription
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSNSSubscriptionFilters = map[string]string{}

func ListSNSSubscription(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSNSSubscription")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSNSSubscriptionPaginator(buildFilter(d.KeyColumnQuals, listSNSSubscriptionFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSNSSubscriptionFilters = map[string]string{
	"subscription_arn": "description.Subscription.SubscriptionArn",
}

func GetSNSSubscription(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSNSSubscription")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSNSSubscriptionPaginator(buildFilter(d.KeyColumnQuals, getSNSSubscriptionFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SNSSubscription =============================

// ==========================  START: SQSQueue =============================

type SQSQueue struct {
	Description   aws.SQSQueueDescription `json:"description"`
	Metadata      aws.Metadata            `json:"metadata"`
	ResourceJobID int                     `json:"resource_job_id"`
	SourceJobID   int                     `json:"source_job_id"`
	ResourceType  string                  `json:"resource_type"`
	SourceType    string                  `json:"source_type"`
	ID            string                  `json:"id"`
	SourceID      string                  `json:"source_id"`
}

type SQSQueueHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  SQSQueue      `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type SQSQueueHits struct {
	Total SearchTotal   `json:"total"`
	Hits  []SQSQueueHit `json:"hits"`
}

type SQSQueueSearchResponse struct {
	PitID string       `json:"pit_id"`
	Hits  SQSQueueHits `json:"hits"`
}

type SQSQueuePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSQSQueuePaginator(filters []BoolFilter, limit *int64) (SQSQueuePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_sqs_queue", filters, limit)
	if err != nil {
		return SQSQueuePaginator{}, err
	}

	p := SQSQueuePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SQSQueuePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SQSQueuePaginator) NextPage(ctx context.Context) ([]SQSQueue, error) {
	var response SQSQueueSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SQSQueue
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSQSQueueFilters = map[string]string{}

func ListSQSQueue(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSQSQueue")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSQSQueuePaginator(buildFilter(d.KeyColumnQuals, listSQSQueueFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSQSQueueFilters = map[string]string{
	"queue_url": "description.Attributes.QueueUrl",
}

func GetSQSQueue(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSQSQueue")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSQSQueuePaginator(buildFilter(d.KeyColumnQuals, getSQSQueueFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SQSQueue =============================

// ==========================  START: S3Bucket =============================

type S3Bucket struct {
	Description   aws.S3BucketDescription `json:"description"`
	Metadata      aws.Metadata            `json:"metadata"`
	ResourceJobID int                     `json:"resource_job_id"`
	SourceJobID   int                     `json:"source_job_id"`
	ResourceType  string                  `json:"resource_type"`
	SourceType    string                  `json:"source_type"`
	ID            string                  `json:"id"`
	SourceID      string                  `json:"source_id"`
}

type S3BucketHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  S3Bucket      `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type S3BucketHits struct {
	Total SearchTotal   `json:"total"`
	Hits  []S3BucketHit `json:"hits"`
}

type S3BucketSearchResponse struct {
	PitID string       `json:"pit_id"`
	Hits  S3BucketHits `json:"hits"`
}

type S3BucketPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewS3BucketPaginator(filters []BoolFilter, limit *int64) (S3BucketPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_s3_bucket", filters, limit)
	if err != nil {
		return S3BucketPaginator{}, err
	}

	p := S3BucketPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p S3BucketPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p S3BucketPaginator) NextPage(ctx context.Context) ([]S3Bucket, error) {
	var response S3BucketSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []S3Bucket
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listS3BucketFilters = map[string]string{}

func ListS3Bucket(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListS3Bucket")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewS3BucketPaginator(buildFilter(d.KeyColumnQuals, listS3BucketFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getS3BucketFilters = map[string]string{
	"name": "description.Bucket.Name",
}

func GetS3Bucket(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetS3Bucket")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewS3BucketPaginator(buildFilter(d.KeyColumnQuals, getS3BucketFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: S3Bucket =============================

// ==========================  START: S3AccountSetting =============================

type S3AccountSetting struct {
	Description   aws.S3AccountSettingDescription `json:"description"`
	Metadata      aws.Metadata                    `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	SourceID      string                          `json:"source_id"`
}

type S3AccountSettingHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  S3AccountSetting `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type S3AccountSettingHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []S3AccountSettingHit `json:"hits"`
}

type S3AccountSettingSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  S3AccountSettingHits `json:"hits"`
}

type S3AccountSettingPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewS3AccountSettingPaginator(filters []BoolFilter, limit *int64) (S3AccountSettingPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_s3_accountsettingdescription", filters, limit)
	if err != nil {
		return S3AccountSettingPaginator{}, err
	}

	p := S3AccountSettingPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p S3AccountSettingPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p S3AccountSettingPaginator) NextPage(ctx context.Context) ([]S3AccountSetting, error) {
	var response S3AccountSettingSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []S3AccountSetting
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listS3AccountSettingFilters = map[string]string{}

func ListS3AccountSetting(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListS3AccountSetting")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewS3AccountSettingPaginator(buildFilter(d.KeyColumnQuals, listS3AccountSettingFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getS3AccountSettingFilters = map[string]string{}

func GetS3AccountSetting(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetS3AccountSetting")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewS3AccountSettingPaginator(buildFilter(d.KeyColumnQuals, getS3AccountSettingFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: S3AccountSetting =============================

// ==========================  START: SageMakerEndpointConfiguration =============================

type SageMakerEndpointConfiguration struct {
	Description   aws.SageMakerEndpointConfigurationDescription `json:"description"`
	Metadata      aws.Metadata                                  `json:"metadata"`
	ResourceJobID int                                           `json:"resource_job_id"`
	SourceJobID   int                                           `json:"source_job_id"`
	ResourceType  string                                        `json:"resource_type"`
	SourceType    string                                        `json:"source_type"`
	ID            string                                        `json:"id"`
	SourceID      string                                        `json:"source_id"`
}

type SageMakerEndpointConfigurationHit struct {
	ID      string                         `json:"_id"`
	Score   float64                        `json:"_score"`
	Index   string                         `json:"_index"`
	Type    string                         `json:"_type"`
	Version int64                          `json:"_version,omitempty"`
	Source  SageMakerEndpointConfiguration `json:"_source"`
	Sort    []interface{}                  `json:"sort"`
}

type SageMakerEndpointConfigurationHits struct {
	Total SearchTotal                         `json:"total"`
	Hits  []SageMakerEndpointConfigurationHit `json:"hits"`
}

type SageMakerEndpointConfigurationSearchResponse struct {
	PitID string                             `json:"pit_id"`
	Hits  SageMakerEndpointConfigurationHits `json:"hits"`
}

type SageMakerEndpointConfigurationPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSageMakerEndpointConfigurationPaginator(filters []BoolFilter, limit *int64) (SageMakerEndpointConfigurationPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_sagemaker_endpointconfiguration", filters, limit)
	if err != nil {
		return SageMakerEndpointConfigurationPaginator{}, err
	}

	p := SageMakerEndpointConfigurationPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SageMakerEndpointConfigurationPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SageMakerEndpointConfigurationPaginator) NextPage(ctx context.Context) ([]SageMakerEndpointConfiguration, error) {
	var response SageMakerEndpointConfigurationSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SageMakerEndpointConfiguration
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSageMakerEndpointConfigurationFilters = map[string]string{}

func ListSageMakerEndpointConfiguration(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSageMakerEndpointConfiguration")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSageMakerEndpointConfigurationPaginator(buildFilter(d.KeyColumnQuals, listSageMakerEndpointConfigurationFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSageMakerEndpointConfigurationFilters = map[string]string{
	"name": "description.EndpointConfig.EndpointConfigName",
}

func GetSageMakerEndpointConfiguration(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSageMakerEndpointConfiguration")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSageMakerEndpointConfigurationPaginator(buildFilter(d.KeyColumnQuals, getSageMakerEndpointConfigurationFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SageMakerEndpointConfiguration =============================

// ==========================  START: SageMakerNotebookInstance =============================

type SageMakerNotebookInstance struct {
	Description   aws.SageMakerNotebookInstanceDescription `json:"description"`
	Metadata      aws.Metadata                             `json:"metadata"`
	ResourceJobID int                                      `json:"resource_job_id"`
	SourceJobID   int                                      `json:"source_job_id"`
	ResourceType  string                                   `json:"resource_type"`
	SourceType    string                                   `json:"source_type"`
	ID            string                                   `json:"id"`
	SourceID      string                                   `json:"source_id"`
}

type SageMakerNotebookInstanceHit struct {
	ID      string                    `json:"_id"`
	Score   float64                   `json:"_score"`
	Index   string                    `json:"_index"`
	Type    string                    `json:"_type"`
	Version int64                     `json:"_version,omitempty"`
	Source  SageMakerNotebookInstance `json:"_source"`
	Sort    []interface{}             `json:"sort"`
}

type SageMakerNotebookInstanceHits struct {
	Total SearchTotal                    `json:"total"`
	Hits  []SageMakerNotebookInstanceHit `json:"hits"`
}

type SageMakerNotebookInstanceSearchResponse struct {
	PitID string                        `json:"pit_id"`
	Hits  SageMakerNotebookInstanceHits `json:"hits"`
}

type SageMakerNotebookInstancePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSageMakerNotebookInstancePaginator(filters []BoolFilter, limit *int64) (SageMakerNotebookInstancePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_sagemaker_notebookinstance", filters, limit)
	if err != nil {
		return SageMakerNotebookInstancePaginator{}, err
	}

	p := SageMakerNotebookInstancePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SageMakerNotebookInstancePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SageMakerNotebookInstancePaginator) NextPage(ctx context.Context) ([]SageMakerNotebookInstance, error) {
	var response SageMakerNotebookInstanceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SageMakerNotebookInstance
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSageMakerNotebookInstanceFilters = map[string]string{}

func ListSageMakerNotebookInstance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSageMakerNotebookInstance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSageMakerNotebookInstancePaginator(buildFilter(d.KeyColumnQuals, listSageMakerNotebookInstanceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSageMakerNotebookInstanceFilters = map[string]string{
	"name": "description.NotebookInstance.NotebookInstanceName",
}

func GetSageMakerNotebookInstance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSageMakerNotebookInstance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSageMakerNotebookInstancePaginator(buildFilter(d.KeyColumnQuals, getSageMakerNotebookInstanceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SageMakerNotebookInstance =============================

// ==========================  START: SecretsManagerSecret =============================

type SecretsManagerSecret struct {
	Description   aws.SecretsManagerSecretDescription `json:"description"`
	Metadata      aws.Metadata                        `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	SourceID      string                              `json:"source_id"`
}

type SecretsManagerSecretHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  SecretsManagerSecret `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type SecretsManagerSecretHits struct {
	Total SearchTotal               `json:"total"`
	Hits  []SecretsManagerSecretHit `json:"hits"`
}

type SecretsManagerSecretSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  SecretsManagerSecretHits `json:"hits"`
}

type SecretsManagerSecretPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSecretsManagerSecretPaginator(filters []BoolFilter, limit *int64) (SecretsManagerSecretPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_secretsmanager_secret", filters, limit)
	if err != nil {
		return SecretsManagerSecretPaginator{}, err
	}

	p := SecretsManagerSecretPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SecretsManagerSecretPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SecretsManagerSecretPaginator) NextPage(ctx context.Context) ([]SecretsManagerSecret, error) {
	var response SecretsManagerSecretSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SecretsManagerSecret
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSecretsManagerSecretFilters = map[string]string{}

func ListSecretsManagerSecret(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSecretsManagerSecret")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSecretsManagerSecretPaginator(buildFilter(d.KeyColumnQuals, listSecretsManagerSecretFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSecretsManagerSecretFilters = map[string]string{
	"arn": "description.Secret.ARN",
}

func GetSecretsManagerSecret(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSecretsManagerSecret")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSecretsManagerSecretPaginator(buildFilter(d.KeyColumnQuals, getSecretsManagerSecretFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SecretsManagerSecret =============================

// ==========================  START: SecurityHubHub =============================

type SecurityHubHub struct {
	Description   aws.SecurityHubHubDescription `json:"description"`
	Metadata      aws.Metadata                  `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	SourceID      string                        `json:"source_id"`
}

type SecurityHubHubHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  SecurityHubHub `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type SecurityHubHubHits struct {
	Total SearchTotal         `json:"total"`
	Hits  []SecurityHubHubHit `json:"hits"`
}

type SecurityHubHubSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  SecurityHubHubHits `json:"hits"`
}

type SecurityHubHubPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSecurityHubHubPaginator(filters []BoolFilter, limit *int64) (SecurityHubHubPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_securityhub_hub", filters, limit)
	if err != nil {
		return SecurityHubHubPaginator{}, err
	}

	p := SecurityHubHubPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SecurityHubHubPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SecurityHubHubPaginator) NextPage(ctx context.Context) ([]SecurityHubHub, error) {
	var response SecurityHubHubSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SecurityHubHub
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSecurityHubHubFilters = map[string]string{}

func ListSecurityHubHub(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSecurityHubHub")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSecurityHubHubPaginator(buildFilter(d.KeyColumnQuals, listSecurityHubHubFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSecurityHubHubFilters = map[string]string{
	"hub_arn": "description.Hub.HubArn",
}

func GetSecurityHubHub(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSecurityHubHub")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSecurityHubHubPaginator(buildFilter(d.KeyColumnQuals, getSecurityHubHubFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SecurityHubHub =============================

// ==========================  START: SSMManagedInstance =============================

type SSMManagedInstance struct {
	Description   aws.SSMManagedInstanceDescription `json:"description"`
	Metadata      aws.Metadata                      `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	SourceID      string                            `json:"source_id"`
}

type SSMManagedInstanceHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  SSMManagedInstance `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type SSMManagedInstanceHits struct {
	Total SearchTotal             `json:"total"`
	Hits  []SSMManagedInstanceHit `json:"hits"`
}

type SSMManagedInstanceSearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  SSMManagedInstanceHits `json:"hits"`
}

type SSMManagedInstancePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSSMManagedInstancePaginator(filters []BoolFilter, limit *int64) (SSMManagedInstancePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ssm_managedinstance", filters, limit)
	if err != nil {
		return SSMManagedInstancePaginator{}, err
	}

	p := SSMManagedInstancePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SSMManagedInstancePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SSMManagedInstancePaginator) NextPage(ctx context.Context) ([]SSMManagedInstance, error) {
	var response SSMManagedInstanceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SSMManagedInstance
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSSMManagedInstanceFilters = map[string]string{}

func ListSSMManagedInstance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSSMManagedInstance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSSMManagedInstancePaginator(buildFilter(d.KeyColumnQuals, listSSMManagedInstanceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSSMManagedInstanceFilters = map[string]string{}

func GetSSMManagedInstance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSSMManagedInstance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSSMManagedInstancePaginator(buildFilter(d.KeyColumnQuals, getSSMManagedInstanceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SSMManagedInstance =============================

// ==========================  START: SSMManagedInstanceCompliance =============================

type SSMManagedInstanceCompliance struct {
	Description   aws.SSMManagedInstanceComplianceDescription `json:"description"`
	Metadata      aws.Metadata                                `json:"metadata"`
	ResourceJobID int                                         `json:"resource_job_id"`
	SourceJobID   int                                         `json:"source_job_id"`
	ResourceType  string                                      `json:"resource_type"`
	SourceType    string                                      `json:"source_type"`
	ID            string                                      `json:"id"`
	SourceID      string                                      `json:"source_id"`
}

type SSMManagedInstanceComplianceHit struct {
	ID      string                       `json:"_id"`
	Score   float64                      `json:"_score"`
	Index   string                       `json:"_index"`
	Type    string                       `json:"_type"`
	Version int64                        `json:"_version,omitempty"`
	Source  SSMManagedInstanceCompliance `json:"_source"`
	Sort    []interface{}                `json:"sort"`
}

type SSMManagedInstanceComplianceHits struct {
	Total SearchTotal                       `json:"total"`
	Hits  []SSMManagedInstanceComplianceHit `json:"hits"`
}

type SSMManagedInstanceComplianceSearchResponse struct {
	PitID string                           `json:"pit_id"`
	Hits  SSMManagedInstanceComplianceHits `json:"hits"`
}

type SSMManagedInstanceCompliancePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSSMManagedInstanceCompliancePaginator(filters []BoolFilter, limit *int64) (SSMManagedInstanceCompliancePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ssm_managedinstancecompliance", filters, limit)
	if err != nil {
		return SSMManagedInstanceCompliancePaginator{}, err
	}

	p := SSMManagedInstanceCompliancePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SSMManagedInstanceCompliancePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SSMManagedInstanceCompliancePaginator) NextPage(ctx context.Context) ([]SSMManagedInstanceCompliance, error) {
	var response SSMManagedInstanceComplianceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SSMManagedInstanceCompliance
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSSMManagedInstanceComplianceFilters = map[string]string{
	"resource_id": "description.ComplianceItem.ResourceId",
}

func ListSSMManagedInstanceCompliance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSSMManagedInstanceCompliance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSSMManagedInstanceCompliancePaginator(buildFilter(d.KeyColumnQuals, listSSMManagedInstanceComplianceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSSMManagedInstanceComplianceFilters = map[string]string{}

func GetSSMManagedInstanceCompliance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSSMManagedInstanceCompliance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSSMManagedInstanceCompliancePaginator(buildFilter(d.KeyColumnQuals, getSSMManagedInstanceComplianceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SSMManagedInstanceCompliance =============================

// ==========================  START: ECSTaskDefinition =============================

type ECSTaskDefinition struct {
	Description   aws.ECSTaskDefinitionDescription `json:"description"`
	Metadata      aws.Metadata                     `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	SourceID      string                           `json:"source_id"`
}

type ECSTaskDefinitionHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  ECSTaskDefinition `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type ECSTaskDefinitionHits struct {
	Total SearchTotal            `json:"total"`
	Hits  []ECSTaskDefinitionHit `json:"hits"`
}

type ECSTaskDefinitionSearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  ECSTaskDefinitionHits `json:"hits"`
}

type ECSTaskDefinitionPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewECSTaskDefinitionPaginator(filters []BoolFilter, limit *int64) (ECSTaskDefinitionPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ecs_taskdefinition", filters, limit)
	if err != nil {
		return ECSTaskDefinitionPaginator{}, err
	}

	p := ECSTaskDefinitionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ECSTaskDefinitionPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ECSTaskDefinitionPaginator) NextPage(ctx context.Context) ([]ECSTaskDefinition, error) {
	var response ECSTaskDefinitionSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ECSTaskDefinition
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listECSTaskDefinitionFilters = map[string]string{}

func ListECSTaskDefinition(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListECSTaskDefinition")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewECSTaskDefinitionPaginator(buildFilter(d.KeyColumnQuals, listECSTaskDefinitionFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getECSTaskDefinitionFilters = map[string]string{
	"task_definition_arn": "description.TaskDefinition.TaskDefinitionArn",
}

func GetECSTaskDefinition(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetECSTaskDefinition")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewECSTaskDefinitionPaginator(buildFilter(d.KeyColumnQuals, getECSTaskDefinitionFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ECSTaskDefinition =============================

// ==========================  START: ECSCluster =============================

type ECSCluster struct {
	Description   aws.ECSClusterDescription `json:"description"`
	Metadata      aws.Metadata              `json:"metadata"`
	ResourceJobID int                       `json:"resource_job_id"`
	SourceJobID   int                       `json:"source_job_id"`
	ResourceType  string                    `json:"resource_type"`
	SourceType    string                    `json:"source_type"`
	ID            string                    `json:"id"`
	SourceID      string                    `json:"source_id"`
}

type ECSClusterHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  ECSCluster    `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type ECSClusterHits struct {
	Total SearchTotal     `json:"total"`
	Hits  []ECSClusterHit `json:"hits"`
}

type ECSClusterSearchResponse struct {
	PitID string         `json:"pit_id"`
	Hits  ECSClusterHits `json:"hits"`
}

type ECSClusterPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewECSClusterPaginator(filters []BoolFilter, limit *int64) (ECSClusterPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ecs_cluster", filters, limit)
	if err != nil {
		return ECSClusterPaginator{}, err
	}

	p := ECSClusterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ECSClusterPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ECSClusterPaginator) NextPage(ctx context.Context) ([]ECSCluster, error) {
	var response ECSClusterSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ECSCluster
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listECSClusterFilters = map[string]string{}

func ListECSCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListECSCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewECSClusterPaginator(buildFilter(d.KeyColumnQuals, listECSClusterFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getECSClusterFilters = map[string]string{
	"cluster_arn": "description.Cluster.ClusterArn",
}

func GetECSCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetECSCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewECSClusterPaginator(buildFilter(d.KeyColumnQuals, getECSClusterFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ECSCluster =============================

// ==========================  START: ECSService =============================

type ECSService struct {
	Description   aws.ECSServiceDescription `json:"description"`
	Metadata      aws.Metadata              `json:"metadata"`
	ResourceJobID int                       `json:"resource_job_id"`
	SourceJobID   int                       `json:"source_job_id"`
	ResourceType  string                    `json:"resource_type"`
	SourceType    string                    `json:"source_type"`
	ID            string                    `json:"id"`
	SourceID      string                    `json:"source_id"`
}

type ECSServiceHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  ECSService    `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type ECSServiceHits struct {
	Total SearchTotal     `json:"total"`
	Hits  []ECSServiceHit `json:"hits"`
}

type ECSServiceSearchResponse struct {
	PitID string         `json:"pit_id"`
	Hits  ECSServiceHits `json:"hits"`
}

type ECSServicePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewECSServicePaginator(filters []BoolFilter, limit *int64) (ECSServicePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ecs_service", filters, limit)
	if err != nil {
		return ECSServicePaginator{}, err
	}

	p := ECSServicePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ECSServicePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ECSServicePaginator) NextPage(ctx context.Context) ([]ECSService, error) {
	var response ECSServiceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ECSService
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listECSServiceFilters = map[string]string{}

func ListECSService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListECSService")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewECSServicePaginator(buildFilter(d.KeyColumnQuals, listECSServiceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getECSServiceFilters = map[string]string{}

func GetECSService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetECSService")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewECSServicePaginator(buildFilter(d.KeyColumnQuals, getECSServiceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ECSService =============================

// ==========================  START: ECSContainerInstance =============================

type ECSContainerInstance struct {
	Description   aws.ECSContainerInstanceDescription `json:"description"`
	Metadata      aws.Metadata                        `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	SourceID      string                              `json:"source_id"`
}

type ECSContainerInstanceHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  ECSContainerInstance `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type ECSContainerInstanceHits struct {
	Total SearchTotal               `json:"total"`
	Hits  []ECSContainerInstanceHit `json:"hits"`
}

type ECSContainerInstanceSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  ECSContainerInstanceHits `json:"hits"`
}

type ECSContainerInstancePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewECSContainerInstancePaginator(filters []BoolFilter, limit *int64) (ECSContainerInstancePaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ecs_containerinstance", filters, limit)
	if err != nil {
		return ECSContainerInstancePaginator{}, err
	}

	p := ECSContainerInstancePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ECSContainerInstancePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ECSContainerInstancePaginator) NextPage(ctx context.Context) ([]ECSContainerInstance, error) {
	var response ECSContainerInstanceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ECSContainerInstance
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listECSContainerInstanceFilters = map[string]string{}

func ListECSContainerInstance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListECSContainerInstance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewECSContainerInstancePaginator(buildFilter(d.KeyColumnQuals, listECSContainerInstanceFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getECSContainerInstanceFilters = map[string]string{}

func GetECSContainerInstance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetECSContainerInstance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewECSContainerInstancePaginator(buildFilter(d.KeyColumnQuals, getECSContainerInstanceFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ECSContainerInstance =============================

// ==========================  START: ECSTaskSet =============================

type ECSTaskSet struct {
	Description   aws.ECSTaskSetDescription `json:"description"`
	Metadata      aws.Metadata              `json:"metadata"`
	ResourceJobID int                       `json:"resource_job_id"`
	SourceJobID   int                       `json:"source_job_id"`
	ResourceType  string                    `json:"resource_type"`
	SourceType    string                    `json:"source_type"`
	ID            string                    `json:"id"`
	SourceID      string                    `json:"source_id"`
}

type ECSTaskSetHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  ECSTaskSet    `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type ECSTaskSetHits struct {
	Total SearchTotal     `json:"total"`
	Hits  []ECSTaskSetHit `json:"hits"`
}

type ECSTaskSetSearchResponse struct {
	PitID string         `json:"pit_id"`
	Hits  ECSTaskSetHits `json:"hits"`
}

type ECSTaskSetPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewECSTaskSetPaginator(filters []BoolFilter, limit *int64) (ECSTaskSetPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ecs_taskset", filters, limit)
	if err != nil {
		return ECSTaskSetPaginator{}, err
	}

	p := ECSTaskSetPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ECSTaskSetPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ECSTaskSetPaginator) NextPage(ctx context.Context) ([]ECSTaskSet, error) {
	var response ECSTaskSetSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ECSTaskSet
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listECSTaskSetFilters = map[string]string{}

func ListECSTaskSet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListECSTaskSet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewECSTaskSetPaginator(buildFilter(d.KeyColumnQuals, listECSTaskSetFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getECSTaskSetFilters = map[string]string{
	"id": "description.TaskSet.Id",
}

func GetECSTaskSet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetECSTaskSet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewECSTaskSetPaginator(buildFilter(d.KeyColumnQuals, getECSTaskSetFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ECSTaskSet =============================

// ==========================  START: EFSFileSystem =============================

type EFSFileSystem struct {
	Description   aws.EFSFileSystemDescription `json:"description"`
	Metadata      aws.Metadata                 `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	SourceID      string                       `json:"source_id"`
}

type EFSFileSystemHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EFSFileSystem `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EFSFileSystemHits struct {
	Total SearchTotal        `json:"total"`
	Hits  []EFSFileSystemHit `json:"hits"`
}

type EFSFileSystemSearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  EFSFileSystemHits `json:"hits"`
}

type EFSFileSystemPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEFSFileSystemPaginator(filters []BoolFilter, limit *int64) (EFSFileSystemPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_efs_filesystem", filters, limit)
	if err != nil {
		return EFSFileSystemPaginator{}, err
	}

	p := EFSFileSystemPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EFSFileSystemPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EFSFileSystemPaginator) NextPage(ctx context.Context) ([]EFSFileSystem, error) {
	var response EFSFileSystemSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EFSFileSystem
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEFSFileSystemFilters = map[string]string{}

func ListEFSFileSystem(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEFSFileSystem")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEFSFileSystemPaginator(buildFilter(d.KeyColumnQuals, listEFSFileSystemFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEFSFileSystemFilters = map[string]string{
	"aws_efs_file_system": "description.FileSystem.FileSystemId",
}

func GetEFSFileSystem(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEFSFileSystem")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEFSFileSystemPaginator(buildFilter(d.KeyColumnQuals, getEFSFileSystemFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EFSFileSystem =============================

// ==========================  START: EKSCluster =============================

type EKSCluster struct {
	Description   aws.EKSClusterDescription `json:"description"`
	Metadata      aws.Metadata              `json:"metadata"`
	ResourceJobID int                       `json:"resource_job_id"`
	SourceJobID   int                       `json:"source_job_id"`
	ResourceType  string                    `json:"resource_type"`
	SourceType    string                    `json:"source_type"`
	ID            string                    `json:"id"`
	SourceID      string                    `json:"source_id"`
}

type EKSClusterHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EKSCluster    `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EKSClusterHits struct {
	Total SearchTotal     `json:"total"`
	Hits  []EKSClusterHit `json:"hits"`
}

type EKSClusterSearchResponse struct {
	PitID string         `json:"pit_id"`
	Hits  EKSClusterHits `json:"hits"`
}

type EKSClusterPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEKSClusterPaginator(filters []BoolFilter, limit *int64) (EKSClusterPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_eks_cluster", filters, limit)
	if err != nil {
		return EKSClusterPaginator{}, err
	}

	p := EKSClusterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EKSClusterPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EKSClusterPaginator) NextPage(ctx context.Context) ([]EKSCluster, error) {
	var response EKSClusterSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EKSCluster
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEKSClusterFilters = map[string]string{}

func ListEKSCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEKSCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEKSClusterPaginator(buildFilter(d.KeyColumnQuals, listEKSClusterFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEKSClusterFilters = map[string]string{
	"name": "description.Cluster.Name",
}

func GetEKSCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEKSCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEKSClusterPaginator(buildFilter(d.KeyColumnQuals, getEKSClusterFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EKSCluster =============================

// ==========================  START: EKSAddon =============================

type EKSAddon struct {
	Description   aws.EKSAddonDescription `json:"description"`
	Metadata      aws.Metadata            `json:"metadata"`
	ResourceJobID int                     `json:"resource_job_id"`
	SourceJobID   int                     `json:"source_job_id"`
	ResourceType  string                  `json:"resource_type"`
	SourceType    string                  `json:"source_type"`
	ID            string                  `json:"id"`
	SourceID      string                  `json:"source_id"`
}

type EKSAddonHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EKSAddon      `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EKSAddonHits struct {
	Total SearchTotal   `json:"total"`
	Hits  []EKSAddonHit `json:"hits"`
}

type EKSAddonSearchResponse struct {
	PitID string       `json:"pit_id"`
	Hits  EKSAddonHits `json:"hits"`
}

type EKSAddonPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEKSAddonPaginator(filters []BoolFilter, limit *int64) (EKSAddonPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_eks_addon", filters, limit)
	if err != nil {
		return EKSAddonPaginator{}, err
	}

	p := EKSAddonPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EKSAddonPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EKSAddonPaginator) NextPage(ctx context.Context) ([]EKSAddon, error) {
	var response EKSAddonSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EKSAddon
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEKSAddonFilters = map[string]string{}

func ListEKSAddon(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEKSAddon")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEKSAddonPaginator(buildFilter(d.KeyColumnQuals, listEKSAddonFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEKSAddonFilters = map[string]string{
	"addon_name":   "description.Addon.AddonName",
	"cluster_name": "description.Addon.ClusterName",
}

func GetEKSAddon(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEKSAddon")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEKSAddonPaginator(buildFilter(d.KeyColumnQuals, getEKSAddonFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EKSAddon =============================

// ==========================  START: EKSIdentityProviderConfig =============================

type EKSIdentityProviderConfig struct {
	Description   aws.EKSIdentityProviderConfigDescription `json:"description"`
	Metadata      aws.Metadata                             `json:"metadata"`
	ResourceJobID int                                      `json:"resource_job_id"`
	SourceJobID   int                                      `json:"source_job_id"`
	ResourceType  string                                   `json:"resource_type"`
	SourceType    string                                   `json:"source_type"`
	ID            string                                   `json:"id"`
	SourceID      string                                   `json:"source_id"`
}

type EKSIdentityProviderConfigHit struct {
	ID      string                    `json:"_id"`
	Score   float64                   `json:"_score"`
	Index   string                    `json:"_index"`
	Type    string                    `json:"_type"`
	Version int64                     `json:"_version,omitempty"`
	Source  EKSIdentityProviderConfig `json:"_source"`
	Sort    []interface{}             `json:"sort"`
}

type EKSIdentityProviderConfigHits struct {
	Total SearchTotal                    `json:"total"`
	Hits  []EKSIdentityProviderConfigHit `json:"hits"`
}

type EKSIdentityProviderConfigSearchResponse struct {
	PitID string                        `json:"pit_id"`
	Hits  EKSIdentityProviderConfigHits `json:"hits"`
}

type EKSIdentityProviderConfigPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEKSIdentityProviderConfigPaginator(filters []BoolFilter, limit *int64) (EKSIdentityProviderConfigPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_eks_identityproviderconfig", filters, limit)
	if err != nil {
		return EKSIdentityProviderConfigPaginator{}, err
	}

	p := EKSIdentityProviderConfigPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EKSIdentityProviderConfigPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EKSIdentityProviderConfigPaginator) NextPage(ctx context.Context) ([]EKSIdentityProviderConfig, error) {
	var response EKSIdentityProviderConfigSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EKSIdentityProviderConfig
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEKSIdentityProviderConfigFilters = map[string]string{}

func ListEKSIdentityProviderConfig(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEKSIdentityProviderConfig")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEKSIdentityProviderConfigPaginator(buildFilter(d.KeyColumnQuals, listEKSIdentityProviderConfigFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEKSIdentityProviderConfigFilters = map[string]string{
	"cluster_name": "description.IdentityProviderConfig.ClusterName",
	"name":         "description.ConfigName",
	"type":         "description.ConfigType",
}

func GetEKSIdentityProviderConfig(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEKSIdentityProviderConfig")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEKSIdentityProviderConfigPaginator(buildFilter(d.KeyColumnQuals, getEKSIdentityProviderConfigFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EKSIdentityProviderConfig =============================

// ==========================  START: EKSNodegroup =============================

type EKSNodegroup struct {
	Description   aws.EKSNodegroupDescription `json:"description"`
	Metadata      aws.Metadata                `json:"metadata"`
	ResourceJobID int                         `json:"resource_job_id"`
	SourceJobID   int                         `json:"source_job_id"`
	ResourceType  string                      `json:"resource_type"`
	SourceType    string                      `json:"source_type"`
	ID            string                      `json:"id"`
	SourceID      string                      `json:"source_id"`
}

type EKSNodegroupHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  EKSNodegroup  `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type EKSNodegroupHits struct {
	Total SearchTotal       `json:"total"`
	Hits  []EKSNodegroupHit `json:"hits"`
}

type EKSNodegroupSearchResponse struct {
	PitID string           `json:"pit_id"`
	Hits  EKSNodegroupHits `json:"hits"`
}

type EKSNodegroupPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEKSNodegroupPaginator(filters []BoolFilter, limit *int64) (EKSNodegroupPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_eks_nodegroup", filters, limit)
	if err != nil {
		return EKSNodegroupPaginator{}, err
	}

	p := EKSNodegroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EKSNodegroupPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EKSNodegroupPaginator) NextPage(ctx context.Context) ([]EKSNodegroup, error) {
	var response EKSNodegroupSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EKSNodegroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEKSNodegroupFilters = map[string]string{}

func ListEKSNodegroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEKSNodegroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEKSNodegroupPaginator(buildFilter(d.KeyColumnQuals, listEKSNodegroupFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEKSNodegroupFilters = map[string]string{
	"nodegroup_name": "description.Nodegroup.NodegroupName",
}

func GetEKSNodegroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEKSNodegroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEKSNodegroupPaginator(buildFilter(d.KeyColumnQuals, getEKSNodegroupFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EKSNodegroup =============================

// ==========================  START: WAFv2WebACL =============================

type WAFv2WebACL struct {
	Description   aws.WAFv2WebACLDescription `json:"description"`
	Metadata      aws.Metadata               `json:"metadata"`
	ResourceJobID int                        `json:"resource_job_id"`
	SourceJobID   int                        `json:"source_job_id"`
	ResourceType  string                     `json:"resource_type"`
	SourceType    string                     `json:"source_type"`
	ID            string                     `json:"id"`
	SourceID      string                     `json:"source_id"`
}

type WAFv2WebACLHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  WAFv2WebACL   `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type WAFv2WebACLHits struct {
	Total SearchTotal      `json:"total"`
	Hits  []WAFv2WebACLHit `json:"hits"`
}

type WAFv2WebACLSearchResponse struct {
	PitID string          `json:"pit_id"`
	Hits  WAFv2WebACLHits `json:"hits"`
}

type WAFv2WebACLPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewWAFv2WebACLPaginator(filters []BoolFilter, limit *int64) (WAFv2WebACLPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_wafv2_webacl", filters, limit)
	if err != nil {
		return WAFv2WebACLPaginator{}, err
	}

	p := WAFv2WebACLPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p WAFv2WebACLPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p WAFv2WebACLPaginator) NextPage(ctx context.Context) ([]WAFv2WebACL, error) {
	var response WAFv2WebACLSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []WAFv2WebACL
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listWAFv2WebACLFilters = map[string]string{}

func ListWAFv2WebACL(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListWAFv2WebACL")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewWAFv2WebACLPaginator(buildFilter(d.KeyColumnQuals, listWAFv2WebACLFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getWAFv2WebACLFilters = map[string]string{
	"id":    "description.WebACL.Id",
	"name":  "description.WebACL.Name",
	"scope": "description.Scope",
}

func GetWAFv2WebACL(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetWAFv2WebACL")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewWAFv2WebACLPaginator(buildFilter(d.KeyColumnQuals, getWAFv2WebACLFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: WAFv2WebACL =============================

// ==========================  START: KMSKey =============================

type KMSKey struct {
	Description   aws.KMSKeyDescription `json:"description"`
	Metadata      aws.Metadata          `json:"metadata"`
	ResourceJobID int                   `json:"resource_job_id"`
	SourceJobID   int                   `json:"source_job_id"`
	ResourceType  string                `json:"resource_type"`
	SourceType    string                `json:"source_type"`
	ID            string                `json:"id"`
	SourceID      string                `json:"source_id"`
}

type KMSKeyHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  KMSKey        `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type KMSKeyHits struct {
	Total SearchTotal `json:"total"`
	Hits  []KMSKeyHit `json:"hits"`
}

type KMSKeySearchResponse struct {
	PitID string     `json:"pit_id"`
	Hits  KMSKeyHits `json:"hits"`
}

type KMSKeyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewKMSKeyPaginator(filters []BoolFilter, limit *int64) (KMSKeyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_kms_key", filters, limit)
	if err != nil {
		return KMSKeyPaginator{}, err
	}

	p := KMSKeyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p KMSKeyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p KMSKeyPaginator) NextPage(ctx context.Context) ([]KMSKey, error) {
	var response KMSKeySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []KMSKey
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listKMSKeyFilters = map[string]string{}

func ListKMSKey(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListKMSKey")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewKMSKeyPaginator(buildFilter(d.KeyColumnQuals, listKMSKeyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getKMSKeyFilters = map[string]string{
	"id": "description.Metadata.KeyId",
}

func GetKMSKey(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetKMSKey")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewKMSKeyPaginator(buildFilter(d.KeyColumnQuals, getKMSKeyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: KMSKey =============================

// ==========================  START: LambdaFunction =============================

type LambdaFunction struct {
	Description   aws.LambdaFunctionDescription `json:"description"`
	Metadata      aws.Metadata                  `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	SourceID      string                        `json:"source_id"`
}

type LambdaFunctionHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  LambdaFunction `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type LambdaFunctionHits struct {
	Total SearchTotal         `json:"total"`
	Hits  []LambdaFunctionHit `json:"hits"`
}

type LambdaFunctionSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  LambdaFunctionHits `json:"hits"`
}

type LambdaFunctionPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewLambdaFunctionPaginator(filters []BoolFilter, limit *int64) (LambdaFunctionPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_lambda_function", filters, limit)
	if err != nil {
		return LambdaFunctionPaginator{}, err
	}

	p := LambdaFunctionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p LambdaFunctionPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p LambdaFunctionPaginator) NextPage(ctx context.Context) ([]LambdaFunction, error) {
	var response LambdaFunctionSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []LambdaFunction
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listLambdaFunctionFilters = map[string]string{}

func ListLambdaFunction(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListLambdaFunction")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewLambdaFunctionPaginator(buildFilter(d.KeyColumnQuals, listLambdaFunctionFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getLambdaFunctionFilters = map[string]string{
	"name": "description.Function.Configuration.FunctionName",
}

func GetLambdaFunction(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetLambdaFunction")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewLambdaFunctionPaginator(buildFilter(d.KeyColumnQuals, getLambdaFunctionFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: LambdaFunction =============================

// ==========================  START: S3AccessPoint =============================

type S3AccessPoint struct {
	Description   aws.S3AccessPointDescription `json:"description"`
	Metadata      aws.Metadata                 `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	SourceID      string                       `json:"source_id"`
}

type S3AccessPointHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  S3AccessPoint `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type S3AccessPointHits struct {
	Total SearchTotal        `json:"total"`
	Hits  []S3AccessPointHit `json:"hits"`
}

type S3AccessPointSearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  S3AccessPointHits `json:"hits"`
}

type S3AccessPointPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewS3AccessPointPaginator(filters []BoolFilter, limit *int64) (S3AccessPointPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_s3_accesspoint", filters, limit)
	if err != nil {
		return S3AccessPointPaginator{}, err
	}

	p := S3AccessPointPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p S3AccessPointPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p S3AccessPointPaginator) NextPage(ctx context.Context) ([]S3AccessPoint, error) {
	var response S3AccessPointSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []S3AccessPoint
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listS3AccessPointFilters = map[string]string{}

func ListS3AccessPoint(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListS3AccessPoint")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewS3AccessPointPaginator(buildFilter(d.KeyColumnQuals, listS3AccessPointFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getS3AccessPointFilters = map[string]string{
	"name":   "description.AccessPoint.Name",
	"region": "metadata.region",
}

func GetS3AccessPoint(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetS3AccessPoint")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewS3AccessPointPaginator(buildFilter(d.KeyColumnQuals, getS3AccessPointFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: S3AccessPoint =============================

// ==========================  START: CostExplorerByAccountMonthly =============================

type CostExplorerByAccountMonthly struct {
	Description   aws.CostExplorerByAccountMonthlyDescription `json:"description"`
	Metadata      aws.Metadata                                `json:"metadata"`
	ResourceJobID int                                         `json:"resource_job_id"`
	SourceJobID   int                                         `json:"source_job_id"`
	ResourceType  string                                      `json:"resource_type"`
	SourceType    string                                      `json:"source_type"`
	ID            string                                      `json:"id"`
	SourceID      string                                      `json:"source_id"`
}

type CostExplorerByAccountMonthlyHit struct {
	ID      string                       `json:"_id"`
	Score   float64                      `json:"_score"`
	Index   string                       `json:"_index"`
	Type    string                       `json:"_type"`
	Version int64                        `json:"_version,omitempty"`
	Source  CostExplorerByAccountMonthly `json:"_source"`
	Sort    []interface{}                `json:"sort"`
}

type CostExplorerByAccountMonthlyHits struct {
	Total SearchTotal                       `json:"total"`
	Hits  []CostExplorerByAccountMonthlyHit `json:"hits"`
}

type CostExplorerByAccountMonthlySearchResponse struct {
	PitID string                           `json:"pit_id"`
	Hits  CostExplorerByAccountMonthlyHits `json:"hits"`
}

type CostExplorerByAccountMonthlyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCostExplorerByAccountMonthlyPaginator(filters []BoolFilter, limit *int64) (CostExplorerByAccountMonthlyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_costexplorer_byaccountmonthly", filters, limit)
	if err != nil {
		return CostExplorerByAccountMonthlyPaginator{}, err
	}

	p := CostExplorerByAccountMonthlyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CostExplorerByAccountMonthlyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CostExplorerByAccountMonthlyPaginator) NextPage(ctx context.Context) ([]CostExplorerByAccountMonthly, error) {
	var response CostExplorerByAccountMonthlySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CostExplorerByAccountMonthly
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCostExplorerByAccountMonthlyFilters = map[string]string{}

func ListCostExplorerByAccountMonthly(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCostExplorerByAccountMonthly")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCostExplorerByAccountMonthlyPaginator(buildFilter(d.KeyColumnQuals, listCostExplorerByAccountMonthlyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCostExplorerByAccountMonthlyFilters = map[string]string{}

func GetCostExplorerByAccountMonthly(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCostExplorerByAccountMonthly")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCostExplorerByAccountMonthlyPaginator(buildFilter(d.KeyColumnQuals, getCostExplorerByAccountMonthlyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CostExplorerByAccountMonthly =============================

// ==========================  START: CostExplorerByServiceMonthly =============================

type CostExplorerByServiceMonthly struct {
	Description   aws.CostExplorerByServiceMonthlyDescription `json:"description"`
	Metadata      aws.Metadata                                `json:"metadata"`
	ResourceJobID int                                         `json:"resource_job_id"`
	SourceJobID   int                                         `json:"source_job_id"`
	ResourceType  string                                      `json:"resource_type"`
	SourceType    string                                      `json:"source_type"`
	ID            string                                      `json:"id"`
	SourceID      string                                      `json:"source_id"`
}

type CostExplorerByServiceMonthlyHit struct {
	ID      string                       `json:"_id"`
	Score   float64                      `json:"_score"`
	Index   string                       `json:"_index"`
	Type    string                       `json:"_type"`
	Version int64                        `json:"_version,omitempty"`
	Source  CostExplorerByServiceMonthly `json:"_source"`
	Sort    []interface{}                `json:"sort"`
}

type CostExplorerByServiceMonthlyHits struct {
	Total SearchTotal                       `json:"total"`
	Hits  []CostExplorerByServiceMonthlyHit `json:"hits"`
}

type CostExplorerByServiceMonthlySearchResponse struct {
	PitID string                           `json:"pit_id"`
	Hits  CostExplorerByServiceMonthlyHits `json:"hits"`
}

type CostExplorerByServiceMonthlyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCostExplorerByServiceMonthlyPaginator(filters []BoolFilter, limit *int64) (CostExplorerByServiceMonthlyPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_costexplorer_byservicemonthly", filters, limit)
	if err != nil {
		return CostExplorerByServiceMonthlyPaginator{}, err
	}

	p := CostExplorerByServiceMonthlyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CostExplorerByServiceMonthlyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CostExplorerByServiceMonthlyPaginator) NextPage(ctx context.Context) ([]CostExplorerByServiceMonthly, error) {
	var response CostExplorerByServiceMonthlySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CostExplorerByServiceMonthly
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCostExplorerByServiceMonthlyFilters = map[string]string{}

func ListCostExplorerByServiceMonthly(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCostExplorerByServiceMonthly")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCostExplorerByServiceMonthlyPaginator(buildFilter(d.KeyColumnQuals, listCostExplorerByServiceMonthlyFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCostExplorerByServiceMonthlyFilters = map[string]string{}

func GetCostExplorerByServiceMonthly(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCostExplorerByServiceMonthly")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCostExplorerByServiceMonthlyPaginator(buildFilter(d.KeyColumnQuals, getCostExplorerByServiceMonthlyFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CostExplorerByServiceMonthly =============================

// ==========================  START: ECRRepository =============================

type ECRRepository struct {
	Description   aws.ECRRepositoryDescription `json:"description"`
	Metadata      aws.Metadata                 `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	SourceID      string                       `json:"source_id"`
}

type ECRRepositoryHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  ECRRepository `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type ECRRepositoryHits struct {
	Total SearchTotal        `json:"total"`
	Hits  []ECRRepositoryHit `json:"hits"`
}

type ECRRepositorySearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  ECRRepositoryHits `json:"hits"`
}

type ECRRepositoryPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewECRRepositoryPaginator(filters []BoolFilter, limit *int64) (ECRRepositoryPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ecr_repository", filters, limit)
	if err != nil {
		return ECRRepositoryPaginator{}, err
	}

	p := ECRRepositoryPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ECRRepositoryPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ECRRepositoryPaginator) NextPage(ctx context.Context) ([]ECRRepository, error) {
	var response ECRRepositorySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ECRRepository
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listECRRepositoryFilters = map[string]string{}

func ListECRRepository(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListECRRepository")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewECRRepositoryPaginator(buildFilter(d.KeyColumnQuals, listECRRepositoryFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getECRRepositoryFilters = map[string]string{
	"repository_name": "description.Repository.RepositoryName",
}

func GetECRRepository(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetECRRepository")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewECRRepositoryPaginator(buildFilter(d.KeyColumnQuals, getECRRepositoryFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ECRRepository =============================

// ==========================  START: ECRPublicRepository =============================

type ECRPublicRepository struct {
	Description   aws.ECRPublicRepositoryDescription `json:"description"`
	Metadata      aws.Metadata                       `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	SourceID      string                             `json:"source_id"`
}

type ECRPublicRepositoryHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  ECRPublicRepository `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type ECRPublicRepositoryHits struct {
	Total SearchTotal              `json:"total"`
	Hits  []ECRPublicRepositoryHit `json:"hits"`
}

type ECRPublicRepositorySearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  ECRPublicRepositoryHits `json:"hits"`
}

type ECRPublicRepositoryPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewECRPublicRepositoryPaginator(filters []BoolFilter, limit *int64) (ECRPublicRepositoryPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ecrpublic_repository", filters, limit)
	if err != nil {
		return ECRPublicRepositoryPaginator{}, err
	}

	p := ECRPublicRepositoryPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ECRPublicRepositoryPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ECRPublicRepositoryPaginator) NextPage(ctx context.Context) ([]ECRPublicRepository, error) {
	var response ECRPublicRepositorySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ECRPublicRepository
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listECRPublicRepositoryFilters = map[string]string{}

func ListECRPublicRepository(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListECRPublicRepository")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewECRPublicRepositoryPaginator(buildFilter(d.KeyColumnQuals, listECRPublicRepositoryFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getECRPublicRepositoryFilters = map[string]string{
	"repository_name": "description.PublicRepository.RepositoryName",
}

func GetECRPublicRepository(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetECRPublicRepository")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewECRPublicRepositoryPaginator(buildFilter(d.KeyColumnQuals, getECRPublicRepositoryFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ECRPublicRepository =============================

// ==========================  START: ECRPublicRegistry =============================

type ECRPublicRegistry struct {
	Description   aws.ECRPublicRegistryDescription `json:"description"`
	Metadata      aws.Metadata                     `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	SourceID      string                           `json:"source_id"`
}

type ECRPublicRegistryHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  ECRPublicRegistry `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type ECRPublicRegistryHits struct {
	Total SearchTotal            `json:"total"`
	Hits  []ECRPublicRegistryHit `json:"hits"`
}

type ECRPublicRegistrySearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  ECRPublicRegistryHits `json:"hits"`
}

type ECRPublicRegistryPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewECRPublicRegistryPaginator(filters []BoolFilter, limit *int64) (ECRPublicRegistryPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_ecrpublic_registry", filters, limit)
	if err != nil {
		return ECRPublicRegistryPaginator{}, err
	}

	p := ECRPublicRegistryPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ECRPublicRegistryPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ECRPublicRegistryPaginator) NextPage(ctx context.Context) ([]ECRPublicRegistry, error) {
	var response ECRPublicRegistrySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ECRPublicRegistry
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listECRPublicRegistryFilters = map[string]string{}

func ListECRPublicRegistry(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListECRPublicRegistry")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewECRPublicRegistryPaginator(buildFilter(d.KeyColumnQuals, listECRPublicRegistryFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getECRPublicRegistryFilters = map[string]string{
	"registry_id": "description.PublicRegistry.RegistryId",
}

func GetECRPublicRegistry(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetECRPublicRegistry")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewECRPublicRegistryPaginator(buildFilter(d.KeyColumnQuals, getECRPublicRegistryFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ECRPublicRegistry =============================

// ==========================  START: EventBridgeBus =============================

type EventBridgeBus struct {
	Description   aws.EventBridgeBusDescription `json:"description"`
	Metadata      aws.Metadata                  `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	SourceID      string                        `json:"source_id"`
}

type EventBridgeBusHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  EventBridgeBus `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type EventBridgeBusHits struct {
	Total SearchTotal         `json:"total"`
	Hits  []EventBridgeBusHit `json:"hits"`
}

type EventBridgeBusSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  EventBridgeBusHits `json:"hits"`
}

type EventBridgeBusPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEventBridgeBusPaginator(filters []BoolFilter, limit *int64) (EventBridgeBusPaginator, error) {
	paginator, err := newPaginator(k.es, "aws_eventbridge_bus", filters, limit)
	if err != nil {
		return EventBridgeBusPaginator{}, err
	}

	p := EventBridgeBusPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EventBridgeBusPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EventBridgeBusPaginator) NextPage(ctx context.Context) ([]EventBridgeBus, error) {
	var response EventBridgeBusSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EventBridgeBus
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEventBridgeBusFilters = map[string]string{}

func ListEventBridgeBus(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEventBridgeBus")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEventBridgeBusPaginator(buildFilter(d.KeyColumnQuals, listEventBridgeBusFilters, "aws", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEventBridgeBusFilters = map[string]string{
	"arn": "description.Bus.Arn",
}

func GetEventBridgeBus(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEventBridgeBus")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEventBridgeBusPaginator(buildFilter(d.KeyColumnQuals, getEventBridgeBusFilters, "aws", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EventBridgeBus =============================
